<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Contrastive Learning Survey (4) — SimSiam</title>
    <url>/2022/04/18/Contrastive-Learning-Survey-4-%E2%80%94-SimSiam/</url>
    <content><![CDATA[<p>This article aims to introduce a new kind of framework in contrastive learning which does not use negative samples.</p>
<p>Paper: Chen, X., &amp; He, K. (2021). Exploring simple siamese representation learning. In <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (pp. 15750-15758). Updated version accessed at: https://arxiv.org/abs/2011.10566</p>
<a id="more"></a>
<h2 id="novelty">Novelty</h2>
<p>Simsiam is not the first framework which does not use negative samples. BYOL (Grill, J. B., Strub, F., Altché, F., Tallec, C., Richemond, P., Buchatskaya, E., ... &amp; Valko, M. (2020). Bootstrap your own latent-a new approach to self-supervised learning. <em>Advances in Neural Information Processing Systems</em>, <em>33</em>, 21271-21284.) is early than it and has already achieved better accuracy on ImageNet. Generally, SimSiam is just a special case of BYOL. But SimSiam’s beautiful subtraction of BYOL makes people realize the essence of success in contrastive learning without negative samples.</p>
<h2 id="note">Note</h2>
<p>Simsiam does very detailed ablation experiments about its used techniques like: stop-gradient, predictor, hypothesis, loss function, batch normalization. If you want to check result plots, I highly recommend reading the original paper and I will not put them in this blog again.</p>
<h2 id="framework">Framework</h2>
<p><img src="simsiam.png"></p>
<p>Just like paper’s name, it is a real simple framework. Model only use a same encoder(encoder + projector) and a predictor.</p>
<p>Predictor is new one which does not decrible in previous article. A predictor is just an extra MLP. Simsiam wants to make the feature from predictor from <span class="math inline">\(x_1\)</span> (augmentation from image x) can be similar with <span class="math inline">\(x_2\)</span>. Hence, its loss function is just cosine similarity.</p>
<p><img src="byol.png"></p>
<p>Figure 2 is BYOL’s architecture. You can see Simsiam is totally same as BYOL, which the only difference is that BYOL uses a Momentum Encoder <span class="math inline">\(y_{\xi}^{\prime}\)</span> , where <span class="math inline">\(\xi \leftarrow \tau \xi+(1-\tau) \theta\)</span></p>
<p>Hence, you can think of SimSiam as just a special case of BYOL when <span class="math inline">\(\gamma = 1\)</span>.</p>
<p>This architecture is very easy to think of, but why was it not first proposed by BYOL until 2020? The biggest problem with training methods without negative samples is that the model will quickly find a shortcut and cause <strong>model collapsing</strong>. Imagine that our encoder only needs to learn to output 0 at this time, the cosine similarity of the loss function is equal to 0, and the model will no longer be updated.</p>
<p>How BYOL and SimSiam solve model collapsing? They both use a trick: <strong>stop gradient</strong>. We will discuss in detail in the following chapter.</p>
<h2 id="loss-function">Loss Function</h2>
<p><span class="math display">\[\mathcal{D}\left(p_{1}, z_{2}\right)=-\frac{p_{1}}{\left\|p_{1}\right\|_{2}} \cdot \frac{z_{2}}{\left\|z_{2}\right\|_{2}}\]</span></p>
<p>Denote that the encoder is <span class="math inline">\(f\)</span>, prediction is <span class="math inline">\(h\)</span>, then we have <span class="math inline">\(p = h(f(x))\)</span>, <span class="math inline">\(z = f(x)\)</span></p>
<p>So the equation is just the cosince similarity of the features between encoder and prediction.</p>
<p><span class="math display">\[\mathcal{L}=\frac{1}{2} \mathcal{D}\left(p_{1}, z_{2}\right)+\frac{1}{2} \mathcal{D}\left(p_{2}, z_{1}\right)\]</span></p>
<p>SimSiam define a summetrized loss like above, where <span class="math inline">\(1, 2\)</span> is the index of two augmentation images from the same image.</p>
<h2 id="stop-gradient">Stop Gradient</h2>
<p>Stop Gradient means that when the model start to do gradient decent, the branch with stop-gradient will be treated as a constant. Hence, the loss function also can be seen as: <span class="math display">\[\mathcal{L}=\frac{1}{2} \mathcal{D}\left(p_{1}, \text { stopgrad }\left(z_{2}\right)\right)+\frac{1}{2} \mathcal{D}\left(p_{2}, \text { stopgrad }\left(z_{1}\right)\right)\]</span></p>
<p>SimSiam has proved that stop-gradient is the key which prevents model from collapsing solutions with every detailed experiments. You can read them in the paper about experiments and results.</p>
<p>Authors’ hypothesis is that:</p>
<blockquote>
<p>SimSiam is an implementation of an Expectation-Maximization (EM) like algorithm.</p>
</blockquote>
<p>The loss function can be like:</p>
<p><span class="math display">\[\mathcal{L}(\theta, \eta)=\mathbb{E}_{x, \mathcal{T}}\left[\left\|\mathcal{F}_{\theta}(\mathcal{T}(x))-\eta_{x}\right\|_{2}^{2}\right]\]</span></p>
<p>I think that what paper writes is very clear and I could not simplify any more:</p>
<blockquote>
<p><img src="hypothesis.png" width="50%" height="50%"></p>
</blockquote>
<p>Than, we can use SGD to solve (7) and get new <span class="math inline">\(\eta_{x}\)</span> by the updated encoder <span class="math inline">\(\mathcal{F}\)</span>.</p>
<p>For the prediction and the complete hypothesis, I highly recommend reading the original paper since I could not simplify them more.</p>
<h2 id="comparision">Comparision</h2>
<p><img src="evaluation.png"></p>
<p>Table 4 is a global table where hasall networks we talked about in the previous chapters. And it clearly showes that SimSiam uses the simplest framework (no negative pair, no momentum encoder, very samll batch size) achieves a good result(68.1% acc) on ImageNet.</p>
<p>Hence, although SimSiam does not have any new techniques, it probably shows the kernel of unsupervised learning in the image domain. Such beautiful subtraction operations and exhaustive experimental evidence earned this work the Best Paper Honorable Mentions of CVPR 2022.</p>
]]></content>
      <categories>
        <category>Contrastive Learning</category>
      </categories>
      <tags>
        <tag>self-supervised learning</tag>
        <tag>computer vision</tag>
      </tags>
  </entry>
  <entry>
    <title>Contrastive Learning Survey (2) — SimCLR</title>
    <url>/2022/03/02/Contrastive-Learning-Survey-2-%E2%80%94-SimCLR/</url>
    <content><![CDATA[<p>This article decribes an end-to-end framework for contrastive learning called SimCLR.</p>
<p>Paper: Ting Chen, Simon Kornblith, Mohammad Norouzi, and Ge- offrey Hinton. A simple framework for contrastive learning of visual representations. <em>arXiv:2002.05709</em>, 2020. Updated version accessed at: https://arxiv.org/abs/2002.05709.</p>
<a id="more"></a>
<h2 id="bottleneck-of-past-work">Bottleneck of past work</h2>
<p>Although InstDisc which we talked in the last chapter proposed a nice pretext task which makes self-supervised learning seems possible in CV field, the accuracy/performance of InstDisc on image-net is not high, which means that the representation learning from InstDisc is not good.</p>
<p><img src="figure1.png" width="50%" height="50%"></p>
<p>Unlike other CV papers that put network structure or images in Figure 1, Figure 1 in simCLR just want to tell people that how good performance simCLR is. Actually, as the name of the paper defines, this is a very simple framework, but it is the first time that unsupervised learning can beat the benchmark supervised model on image-net, which demonstrates the power and confidence of unsupervised learning.</p>
<h2 id="model-framework">Model Framework</h2>
<p><img src="figure2.png" width="50%" height="50%"></p>
<p>If Figure 2 is hard to understand, here is a structure drawn by me.</p>
<p><img src="simCLR_framework.jpg" width="50%" height="50%"></p>
<p>The difference from InstDisc to simCLR is that it straightly uses images in the same batch as negative samples instead of using memory bank. In this way, all image vectors are obtained from the same encoder every time, which naturally solves the problem of inconsistent feature distribution in InstDisc.</p>
<h2 id="model-insights">Model Insights</h2>
<blockquote>
<ol type="1">
<li>Composition of multiple data augmentation operations is crucial in defining the contrastive prediction tasks that yield effective representations. In addition, unsupervised contrastive learning benefits from stronger data augmentation than supervised learning.</li>
<li>Introducing a learnable nonlinear transformation between the representation and the contrastive loss substantially improves the quality of the learned representations.</li>
<li>Representation learning with contrastive cross entropy loss benefits from normalized embeddings and an appropriately adjusted temperature parameter.</li>
<li>Contrastive learning benefits from larger batch sizes and longer training compared to its supervised counterpart. Like supervised learning, contrastive learning benefits from deeper and wider networks.</li>
</ol>
</blockquote>
<p>These 4 insights are the most important essence of this paper. We will discuss in detail one by one.</p>
<h3 id="data-augmentation">Data augmentation</h3>
<p>The first insight demonstrates that data guamentation is an important condition for a successful training in contrastive learning.</p>
<p><img src="augmentation.png" width="50%" height="50%"></p>
<p>Figure 5 shows that the combination of <strong>random cropping and random color distortion</strong> is the best data augmentation for improving accuracy. This result makes almost all subsequent comparative learning work use this data augmentation strategy.</p>
<p>Moreover, it conjectures that:</p>
<blockquote>
<p>one serious issue when using only random cropping as data augmentation is that most patches from an image share a similar color distribution. Neural nets may exploit this shortcut to solve the predictive task. Therefore, it is critical to compose cropping with color distortion in order to learn generalizable features.</p>
</blockquote>
<p>The original paper shows very detailed augmentation strategy and experiment results to prove this point in chapter 3.1, 3.2.</p>
<h3 id="projection">Projection</h3>
<p><img src="projector.png" width="50%" height="50%"></p>
<p>Projection is just a single dense layer with ReLu and is used bewteen the output of encoder and the input of loss function. It can make the outputs of encoder smoother. The experiment results show that add a nonlinear projector(one dense layer + Relu) improves accuracy a lot.</p>
<blockquote>
<p>We observe that a nonlinear projection is better than a linear projection (+3%), and much better than no projection (&gt;10%).</p>
</blockquote>
<p>Another interesting result is that:</p>
<blockquote>
<p>Furthermore, even when nonlinear projection is used, the layer before the projection head, h, is still much better (&gt;10%) than the layer after, z = g(h), which shows that <em>the hidden layer before the projection head is a better representation than the layer after</em>.</p>
</blockquote>
<p>which means that projection is really usefull for contrastive learning.</p>
<h3 id="hyperparameters">Hyperparameters</h3>
<p><img src="hyperparameters.png" width="50%" height="50%"></p>
<p>Table 5 shows that temperature <span class="math inline">\(\tau\)</span> has a strong effect on accuracy. Also, if model is trained without l2 norm, it may overfit (much higher in contrastive acc but low acc in downstream tasks).</p>
<p>In conclusion, this part talks more about tricks. It proves that <span class="math inline">\(\tau\)</span> is an important hyper parameter and l2 norm help representation learning.</p>
<p>Actually, this chapter in the paper also describes about the loss function. But I decided to dedicate a specialized article for all loss functions in contrastive learning. We will talk it in that article.</p>
<h3 id="huge-negative-samples">Huge negative samples</h3>
<p><img src="negative_size.png" width="50%" height="50%"></p>
<p>Figure 9 shows that the accuracy of simCLR increases significantly with the increase of batch size. Since the size of batch size is the size of negative samples, the paper says that a huge negative sample set is the key to improving the performance of contrastive learning.</p>
<p>However, if you use a batch size which is more than 1024 to train, it requires huge calculation recourses and many tricks to make it start training. Hence, simCLR is hard to preproduce by ourselves and hard to land in real scene.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Although simCLR almost can not be preproduced and landed, it proves many useful tricks and insights for contrastive learning. Hence, simCLR has a huge impact on follow-up research due to its easy framework and strong results.</p>
]]></content>
      <categories>
        <category>Contrastive Learning</category>
      </categories>
      <tags>
        <tag>self-supervised learning</tag>
        <tag>computer vision</tag>
      </tags>
  </entry>
  <entry>
    <title>Contrastive Learning Survey (3) — MoCo</title>
    <url>/2022/03/05/Contrastive-Learning-Survey-3-%E2%80%94-MoCo/</url>
    <content><![CDATA[<p>This article decribes a milestone in contrastive learning and the best paper <strong>Nominee</strong> in CVPR 2020.</p>
<p>Paper: He, K., Fan, H., Wu, Y., Xie, S., and Girshick, R. Momentum contrast for unsupervised visual representation learning. <em>arXiv preprint arXiv:1911.05722</em>, 2019. Updated version accessed at: https://arxiv.org/abs/1911.05722.</p>
<a id="more"></a>
<h2 id="bottleneck-of-past-work">Bottleneck of past work</h2>
<p>The requirement of huge batch size makes simCLR hard to land in real scenes. This paper proposes a framework called MoCo which can not only overcome feature consistency but also provide a large negative samples for training.</p>
<h2 id="model-framework">Model Framework</h2>
<p><img src="figure1.png" width="50%" height="50%"></p>
<p>As usual, a CV paper can roughly understand what the paper wants to express through Figure 1.</p>
<p>A quick review of simCLR:</p>
<p><img src="simCLR_framework.jpg" width="50%" height="50%"></p>
<p>The only difference is that MoCo uses a momentum encoder instead of two same encoders.</p>
<p>Note: simCLR and MoCo are the same period work, and in MoCo V2, projector which is proposed by simCLR is used.</p>
<h2 id="queue-to-save-negative-samples">Queue to save negative samples</h2>
<p>We have talked about the cons of InstDisc: inconsistency of negative samples since fast updating encoders; SimCLR: very large batch size to keep negative samples have consistent distribution with positive samples.</p>
<p>To overcome these bottlenecks, Moco wants to have a large dictionary to save negative samples, where these negative samples also are <strong>kept as consistent as possible despite its evolution</strong>. proposed to use a queue to save negative samples by using queue’s FIFO(first in first out) characteristic. Then, a queue with much larger size than batch size is used and you can use small batch size to train networks.</p>
<p>The queue size is recommended as 65536. And after each batch, the earliest negative samples with batch size(n) in the queue will be deleted, and the latest n negative samples will be added to the queue to keep the queue updated.</p>
<p>So far, this queue seems to be like memory bank in InstDisc. And how negative samples in this queue can have same consistency will be discussed in next chapter: a momentum encoder.</p>
<h2 id="momentum-encoder">Momentum encoder</h2>
<p>A momentum encoder is like:</p>
<p><span class="math display">\[\theta_{\mathrm{k}} \leftarrow m \theta_{\mathrm{k}}+(1-m) \theta_{\mathrm{q}}\]</span></p>
<p>where <span class="math inline">\(\theta_{\mathrm{k}}\)</span> is momentum encoder, <span class="math inline">\(\theta_{\mathrm{q}}\)</span> is the encoder updated by back-propagation. <span class="math inline">\(m\)</span> always equals 0.999. Hence, the momentum encoder is updated very slowly and ensure that the negative samples from <span class="math inline">\(\theta_{\mathrm{k}}\)</span> are kept consistency.</p>
<h2 id="loss-function">Loss Function</h2>
<p><span class="math display">\[\mathcal{L}_{q}=-\log \frac{\exp \left(q \cdot k_{+} / \tau\right)}{\sum_{i=0}^{K} \exp \left(q \cdot k_{i} / \tau\right)}\]</span></p>
<p>Moco proposed infoNCE loss and soon become the mainstream loss in contrastive learning. The only difference between NCE loss and infoNCE loss is that infoNCE only uses K negative samples from instead of all negative samples.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Moco achieves 68.6% accuracy by linear classification protocol on ImageNet. Compared with 54% in InstDice, Moco can be regarded as a milestone work in contrastive learning.</p>
]]></content>
      <categories>
        <category>Contrastive Learning</category>
      </categories>
      <tags>
        <tag>self-supervised learning</tag>
        <tag>computer vision</tag>
      </tags>
  </entry>
  <entry>
    <title>Contrastive Learning Survey (1) — InstDisc</title>
    <url>/2022/02/24/Contrastive-Learning-Survey-1-%E2%80%94-InstDisc/</url>
    <content><![CDATA[<p>This article aims to introduce the pioneering work (InstDisc) that leads to contrastive learning.</p>
<p>Paper: Zhirong Wu, Yuanjun Xiong, Stella Yu, and Dahua Lin. Unsupervised feature learning via non-parametric instance discrimination. In CVPR, 2018. Updated version accessed at: https://arxiv.org/abs/1805.01978v1.</p>
<a id="more"></a>
<h1 id="why-this-paper">Why this paper?</h1>
<p>Self-supervised models such as BERT/GPT have been used with great success in the NLP field. However, supervised learning still occupies most of the work in the CV field. Researchers hope to find a kind of pretext task in the image domain to complete self-supervised learning, just like MASK in the NLP domain. This paper creatively proposes a pretext task called <strong>instance discrimination</strong> which performs well and is still the most mainstream pretext task for contrastive learning so far.</p>
<p>Although techniques about the loss function, how negative samples are stored in this paper are obsolete, the pretext task and the framework in this paper has a milestone significance in the history of contrastive learning and has influenced most of the subsequent work.</p>
<p>Hence, I choose this paper as the first one in this series of the survey of contrastive learning.</p>
<h1 id="research-motivation">Research Motivation</h1>
<p><img src="figure1.png" width="50%" height="50%"></p>
<p>Paper’s Figure 1 is very clear to show the motivation. Authors find that:</p>
<blockquote>
<p>For an image from class <em>leopard</em>, the classes that get highest responses from a trained neural net classifier are all visually correlated, e.g., <em>jaguar</em> and <em>cheetah</em>. It is not the semantic labeling, but the apparent similarity in the data themselves that brings some classes closer than others.</p>
</blockquote>
<p>Hence, they want to:</p>
<blockquote>
<p>Our unsupervised approach takes the class-wise supervision to the extreme and learns a feature representation that discriminates among individual instances.</p>
</blockquote>
<p>In other words, contrastive learning is also called representation learning which aims to find an image vector(like word vector in NLP) which represents image semantic in a high dimension by unsupervised learning. And then, you can use these vector in your custom downstream tasks with a small annotated dataset.</p>
<h1 id="model-overview">Model Overview</h1>
<p><img src="figure2.png"></p>
<p>Figure 2 shows a clear pipeline of the model inference. Now I will describe each part of them and try to make you understand easier.</p>
<h2 id="instance-discrimination">Instance Discrimination</h2>
<p>As figure 1 says, we want to get a vertor which similar images are close in a high dimension(128 in this paper) and not similar images are far way from each other without using annotated images. However, although InstDict model is called as a unsupervised model, they actually still uses label. The method they use is really tricky that they take every image as a class and the task is to distinguish every image instance. This task sounds useless, and yes they are. So this kind of task is named as pretext task, which the aim of them is just to let the model can be trained.</p>
<p><img src="InstDisc.png"></p>
<p>Above figure shows that a pipline of instance discrimination. An instance, in this example , is an image of a unqiue cat. it will be transferred by image augmentation into 2 images: cropped one and rotated one. These two represent the same cat and so the image vector of these 2 images should be similar in our model, and vertors of other images in red square should be quite different from these 2images. What you find? Yes, we get positive and negative sample by this kind of easy implementation. Usually, in contrastive learning, we call the “cropped cat” (one of the augmentation image) Query, and the combination of the other augmentation image and the rest images is called Keys. Hence, our aim is to find a key in keys which is most similar with the query.</p>
<p>To conclusion, instance discrimination is a tricky pretext task which make the images without labels can have similar label by using image augmentation.</p>
<p>Pros: easy to implementation, good explanation, proved to be useful</p>
<p>Cons: the negative samples may contain the positive sample(image another cat image is included but it will be treated as a negative sample in instance discrimination task)</p>
<h2 id="loss-function-nce-loss">Loss Function: NCE loss</h2>
<p><span class="math display">\[Loss = -\log\frac{\exp \left(\mathbf{v}_{i}^{T} \mathbf{v} / \tau\right)}{\sum_{j=1}^{n} \exp \left(\mathbf{v}_{j}^{T} \mathbf{v} / \tau\right)}\]</span></p>
<p><span class="math inline">\(v_i\)</span> is query, <span class="math inline">\(v\)</span> is positive key, <span class="math inline">\(v_j\)</span> are negative keys. The loss function is similar with Cross Entropy Softmax.</p>
<p>Actually, InfoNCE is totally the same as NCE loss, which infoNCE uses n (n &lt; j) samples instead of all negative samples to make calculation faster.</p>
<h2 id="memory-bank">Memory Bank</h2>
<p>Another important work in InstDisc is that it proposed a data structure called memory bank, which stored all images’ 128d vectors, also the <span class="math inline">\(v_j\)</span> in the loss function.</p>
<p>Pipeline in Paper:</p>
<blockquote>
<p>Let V = {vj} be the memory bank and fi = fθ(xi) be the feature of xi. During each learning itera- tion, the representation fi as well as the network parameters θ are optimized via stochastic gradient descend. Then fi is updated to V at the corresponding instance entry fi → vi. We initialize all the representations in the memory bank V as unit random vectors.</p>
</blockquote>
<p>A more clear flowchart:</p>
<p><img src="memory%20bank.png"></p>
<p>Pros: The number of negative samples in the previous comparative learning is not enough because it is strongly related to the batch size. Memory bank liberates this limation. In this paper, Each time nce loss is calculated, 4096 negative samples are randomly selected from the memory bank.</p>
<p>Cons: encoder network may update too quickly to make the distribution between image vectors has a large difference.</p>
<h2 id="evaluation">Evaluation</h2>
<p>Since contrastive learning is unsupervised learning and aims to learn good representation feature of images, we cannot directly assess the accuracy of the model.</p>
<p>InstDisc uses <strong>linear SVM</strong> and <strong>KNN</strong> to evaluate model performance. Simply, it is to use the encoder after model training as a feature extractor, and train a svm or knn on the features of the image after the encoder to evaluate model performance.</p>
<p>However, since this is a contrastive learning survey, I want to describe a more popular way in later works: <strong>Linear Classification Protocol</strong>. This method also freezes features from trained encoder, and train a supervised linear classifier(a fully-connected layer followed by softmax) and evualte different models between supervised and unspervised models. And ImageNet is always used as evaluation method.</p>
<p>InstDisc only has 54% accuracy on ImageNet by linear classification, which is much lower than supervised model. But it is a groundbeaking work and the following contrastive models have achieved the same performance with supervised model.</p>
<p>We will have a global description of model performance after we has discussed several classic contrastive learning models in following chapters.</p>
<h2 id="conclusion">Conclusion</h2>
<p>We describe the pretext task: Instance Discrimination, model pipeline, a brief of NCE loss and Memory bank. Actually, this paper also proposed other technique skills, but these techniques have little inspiration for follow-up research.</p>
<p>Next blog we will continue discussing another kinds of contrastive learning framework which are different from InstDisc.</p>
]]></content>
      <categories>
        <category>Contrastive Learning</category>
      </categories>
      <tags>
        <tag>self-supervised learning</tag>
        <tag>computer vision</tag>
      </tags>
  </entry>
  <entry>
    <title>Contrastive Learning Survey (5) — Contrastive Learning with Clustering</title>
    <url>/2022/05/06/Contrastive-Learning-Survey-5-%E2%80%94-Contrastive%20Learning%20with%20Clustering/</url>
    <content><![CDATA[<p>So far, we have discussed Contrastive Learning(CL) frameworks such as InstDisc, SimCLR, MoCo, SimSiam, BYOL, which still the mainstream framework in the lastest CL works. Instead of frameworks, CL still has many also problems or weakness. This chapter will discribe one of it weakness: lacking semantic presententation due to instance discrimination pretext task, i.e. a model good at discriminating instances will lose higher level information like their clusters. Therefore, let’s see how researchers integrate clustering methods into Contrastive Learning. Moreover, this chapter and the next will be like a short survey of the lastest CL papers, which means I will not write every paper clearly and discuss every techniques. We will focus on papers’ motivation, main method and try to give my own insights.</p>
<a id="more"></a>
<h2 id="swav">SWaV</h2>
<p>To be improved.</p>
<h2 id="pcl-prototypical-contrastive-learning">PCL: PROTOTYPICAL CONTRASTIVE LEARNING</h2>
<p>Paper: Li J, Zhou P, Xiong C, et al. Prototypical contrastive learning of unsupervised representations[J]. arXiv preprint arXiv:2005.04966, 2020.</p>
<p>Arxiv: https://arxiv.org/abs/2005.04966</p>
<p>This paper proposes 2 drawbacks of previous contrastive learning framework.</p>
<ol type="1">
<li><blockquote>
<p>The task of instance discrimination could be solved by exploiting low-level image differences, thus the learned embeddings do not necessarily capture high-level semantics. This is supported by the fact thatthe accuracy of instance classification often rapidly rises to a high level (&gt;90% within 10 epochs) and further training gives limited informative signals. A recent study also shows that better performance of instance discrimination could worsen the performance on downstream tasks.</p>
</blockquote></li>
<li>cannot capture the semantic structure of data, since each negative sample shares similar semantics by InfoNCE.</li>
</ol>
<h3 id="framework">Framework</h3>
<p><img src="PCL/framework.png"></p>
<p><img src="PCL/pseudo_code.png"></p>
<p>Figure 2 and pseudo-code can help understand PCL:</p>
<ol type="1">
<li>use features from momentum encoder to do k-means to get prototypes/cluster centers and concentration(discuss later).</li>
<li>Use ProtoNCE to update network, which ProtoNCE will use prototypes by the previous step.</li>
<li>update momentum encoder like MoCo</li>
</ol>
<h3 id="protonce">ProtoNCE</h3>
<p><span class="math display">\[\mathcal{L}_{\text {ProtoNCE }}=\sum_{i=1}^{n}-\left(\log \frac{\exp \left(v_{i} \cdot v_{i}^{\prime} / \tau\right)}{\sum_{j=0}^{r} \exp \left(v_{i} \cdot v_{j}^{\prime} / \tau\right)}+\frac{1}{M} \sum_{m=1}^{M} \log \frac{\exp \left(v_{i} \cdot c_{s}^{m} / \phi_{s}^{m}\right)}{\sum_{j=0}^{r} \exp \left(v_{i} \cdot c_{j}^{m} / \phi_{j}^{m}\right)}\right)\]</span></p>
<p>where <span class="math inline">\(c\)</span> is cluster information. So this loss combines between Clusters info and Instances Info. <span class="math inline">\(M\)</span> means that they will do k-means M times or M different k clusters, they proposed that M times k-means will have different propotype semantic structure from high semantice to low semantic.</p>
<p>Another different paramter is <span class="math inline">\(\phi\)</span>, where it always is a hyperparamter of <span class="math inline">\(\tau\)</span>. Here <span class="math inline">\(\phi\)</span> is a dynamic paramter learning with training.</p>
<p><span class="math display">\[\phi=\frac{\sum_{z=1}^{Z}\left\|v_{z}^{\prime}-c\right\| 2}{Z \log (Z+\alpha)}\]</span></p>
<p>where <span class="math inline">\(α\)</span> is a smooth parameter to ensure that small clusters do not have an overly-large <span class="math inline">\(\phi\)</span>. They normalize <span class="math inline">\(\phi\)</span> for each set of prototypes <span class="math inline">\(C_m\)</span> such that they have a mean of <span class="math inline">\(\tau\)</span>.</p>
<h2 id="hcsc-hierarchical-contrastive-selective-coding">HCSC: Hierarchical Contrastive Selective Coding</h2>
<p><img src="HCSC/figure1.png" width="75%" height="75%"></p>
<p>This paper proposed that a large dataset contains multiple semantic, e.g. “mammals <span class="math inline">\(\to\)</span> Dogs <span class="math inline">\(\to\)</span> Labradors”, where this kind of hierarachical semantics do not be noticed in previous researches. Actucally, PCL does this like multiple times k-means. But this paper does more work on this.</p>
<p>Another novelty job is that they propose to select high-quality positive and negative pairs which confirms that they are true negative and positive samples.</p>
<p>For positive samples: select most similar prototype on each semantic hierarchy to build more abundant positive pairs.</p>
<p>For negative samples: use a Bernoulli sampling to determine if a sample is kept or discarded by their semantic correlation value.</p>
<p>### Hierarchical K-means</p>
<p><img src="HCSC/hierarchical_k_means.png" width="50%" height="50%"></p>
<p>The difference between HCSC and PCL is that they iterate k-means in the clusters, where PCL do gobal k-means many times.</p>
<h3 id="sample-selecting">Sample selecting</h3>
<p><img src="HCSC/sample_method.png"></p>
<p>For example, mammals will be a global semantic which be shown as a biggest green point. Then “dogs” will be “mammals” branch and be shown as a smaller green point, and “poodles” and “labradors” will be shown as the smallest green points. Every other different color points are those who are different with “Mammals”.</p>
<p>For (b), when selecting samples, positive pairs will be selected in all green points with different sizes to ensure they have different hierarchical semantic, e.g. not only the augs from themselves, but also “poodles”, “dogs”, “mammals” for a “labradors” image. And Negative pairs will be selected in different color points and sample them by a Bernoulli sampling (dicuss later).</p>
<p><strong>selecting code</strong></p>
<p><strong>selecting example</strong></p>
<p><img src="HCSC/query.png" width="75%" height="75%"></p>
<p><img src="HCSC/cluster.png"></p>
]]></content>
      <categories>
        <category>Contrastive Learning</category>
      </categories>
      <tags>
        <tag>self-supervised learning</tag>
        <tag>computer vision</tag>
      </tags>
  </entry>
  <entry>
    <title>Contrastive Learning Survey (7) — Contrastive Learning theory</title>
    <url>/2022/05/19/Contrastive-Learning-Survey-7-%E2%80%94-Contrastive-Learning-theory/</url>
    <content><![CDATA[<p>Why Contrastive Learning can work? It is also an interesting field and has many excellent papers.</p>
<p>At present, <strong>mutual information</strong> is a key point in my cognition. Of course, this chapter will continue to be updated as my research progresses.</p>
<a id="more"></a>
<h2 id="what-makes-for-good-views-for-contrastive-learning">What Makes for Good Views for Contrastive Learning</h2>
<h2 id="demystifying-self-supervised-learning-an-information-theoretical-framework">Demystifying Self-Supervised Learning: An Information-Theoretical Framework</h2>
<h2 id="on-mutual-information-in-contrastive-learning-for-visual-representations">On Mutual Information in Contrastive Learning for Visual Representations</h2>
]]></content>
      <categories>
        <category>Contrastive Learning</category>
      </categories>
      <tags>
        <tag>self-supervised learning</tag>
        <tag>computer vision</tag>
      </tags>
  </entry>
  <entry>
    <title>Contrastive Learning Survey (8) — Contrastive Learning bottlenecks</title>
    <url>/2023/02/05/Contrastive-Learning-Survey-8-%E2%80%94-Contrastive%20Learning%20bottlenecks/</url>
    <content><![CDATA[<p>What are common drawbacks for the present contrastive learning methods?</p>
<p>When Does Contrastive Visual Representation Learning Work?</p>
<p>[<a href="https://arxiv.org/abs/2105.05837v1" target="_blank" rel="noopener">2105.05837v1] When Does Contrastive Visual Representation Learning Work? (arxiv.org)</a></p>
<a id="more"></a>
<h1 id="contrastive-learning-survey-8-contrastive-learning-bottlenecks">Contrastive Learning Survey (8) — Contrastive Learning bottlenecks</h1>
<p>[<a href="https://arxiv.org/abs/2105.05837v1" target="_blank" rel="noopener">2105.05837v1] When Does Contrastive Visual Representation Learning Work? (arxiv.org)</a></p>
<p>This paper indicates 4 bottlenecks of current contrastive learning framework: dataset size, domain, quality and task granularity.</p>
<p><img src="topics.png"></p>
<h2 id="dataset-size">Dataset Size</h2>
<p><strong>How much data is required to learn a “good” representation?</strong></p>
<p>This paper compares the accuracy between 3 datasets from contrastive learning and supervised learning to answer this question.</p>
<p><img src="gap.png"></p>
<p>The experiments concludes that:</p>
<ol type="1">
<li>There is little benefit beyond 500k pretraining images.</li>
<li>Self-supervised pretraining can be a good initializer when there is limited supervision available.</li>
<li>Self-supervised representations can approach fully supervised performance for some datasets, but only by using lots of labeled images.</li>
</ol>
<p>PS: the large gap between supervised and self-supervised performance on iNat21 in the high data regime suggests that iNat21 could be a useful benchmark for future self-supervised learning research. The high supervised performance shows that the task is possible, and yet the self-supervised performance remains quite low.</p>
<h2 id="data-domain">Data domain</h2>
<p><strong>What kind of images should we use for pretraining?</strong></p>
<ol type="1">
<li><p>Not all pretraining sets are created equal.</p>
<p><img src="result1.png"></p></li>
<li><p>Adding cross-domain data does not necessarily lead to more capable representations.</p>
<p><img src="result2.png"></p></li>
<li><p>Different representations are seldom complementary.</p>
<p><img src="result3.png"></p>
<p>The kinds of images used for self-supervised pretraining can have a significant impact on the learned representations.</p></li>
</ol>
<h2 id="data-quality">Data quality</h2>
<p><img src="result4.png"></p>
<ol type="1">
<li>Image resolution is critical.</li>
<li>Adding high-frequency noise is much less harmful than erasing high frequency information.</li>
</ol>
<p>Contrastive learning is sensitive for image resolution, while supervised learning is sensitive for JPEG compression.</p>
<h2 id="task-granularity">Task granularity</h2>
<p><strong>Whether there are some downstream tasks for which self-supervised representations are particularly well or poorly suited.</strong></p>
<p><img src="result5.png"></p>
<ol type="1">
<li><p>The performance gap between contrastive learning and supervised learning grows as task granularity increases</p></li>
<li><p>Are the augmentations mis-specified?</p>
<p>The augmentation strategy of simCLR is for Image-net, so the default augmentation policy may be poorly tuned for other datasets.</p></li>
<li><p>Does contrastive learning have a coarse-grained bias?</p></li>
</ol>
<p>Conclusion: we should find a new pretext task which is more suitable for fine-grained bias.</p>
]]></content>
      <categories>
        <category>Contrastive Learning</category>
      </categories>
      <tags>
        <tag>self-supervised learning</tag>
        <tag>computer vision</tag>
      </tags>
  </entry>
  <entry>
    <title>Writing Task 1: Bar Chart</title>
    <url>/2022/06/05/Writing-Task-1-Bar-Chart/</url>
    <content><![CDATA[<p>Bar chart writing skills</p>
<a id="more"></a>
<h2 id="summary">Summary</h2>
<ol type="1">
<li><p>paraphrase the question (introduction)</p></li>
<li><p>make a general comparison (overview)</p>
<p>the green part</p>
<p><img src="overview.png" width="50%" height="50%"></p></li>
<li><p>Compare specific numbers (details)</p>
<p>lot of comparisons by showing numbers</p></li>
</ol>
<h2 id="example">Example</h2>
<p><img src="example.png"></p>
<p><strong>Introduction</strong>:</p>
<p>Question:</p>
<p>The chart below shows global sales of the top five mobile phone brands between 2009 and 2013.</p>
<p>Practice:</p>
<p>The bar chart compares global mobile phone sales using 5 popular brands over a period of 4 years.</p>
<p>Template:</p>
<p>The bar chart compares the number of mobile phone sold worldwide by the five most popular manufacturers in the years 2009, 2011 and 2013.</p>
<p><strong>Overview</strong>: 2 sentences, 2 main points</p>
<p>Practice:</p>
<p>In 2009 and 2011, the sales of mobile phones made by Nokia were significantly greater than other brands. However, Samsung became the most popular mobile phone brand in the world in 2013.</p>
<p>Template:</p>
<p>It is clear that Nokia sold the most mobile phones between 2009 and 2011, but Samsung became the best selling brand in 2013. Samsung and Apple saw the biggest rises in sales over the 5-year period.</p>
<p><strong>Details in P3</strong>:</p>
<p>Practice:</p>
<p>In 2009, Nokia sold nearly 450 mobile phones, which was almost double the number of handset sales of Samsung, which was the second manufacturer at that time. But after 4 years, Nokia fell nearly 200 units sold which was also the number of Samsung’s increasing sold. By 2013, mobile pyhone sales of Samsung had reached 450 million units and became the market leader.</p>
<p>Template:</p>
<p>In 2009, Nokia sold close to 450 million mobile phones, which was <strong>almost double</strong> the number of handsets sold by the <strong>second most successful</strong> manufacturer, Samsung. Over the following four years, however, Nokia’s sales figures fell by approximately 200 million units, <strong>whereas</strong> Samsung saw sales rise by a similar amount. By 2013, Samsung had <strong>became the marker leader</strong> with sales reaching 450 million units.</p>
<p>Review:</p>
<p>In 2009, Nokia sold close to 450 million mobile phones, which was almost double the number of handsets sold by the second successful manufacturer, Samsung. Over the following four years, however, <strong>Nokia’s sales figures</strong> fell by approximately 200 million units, whereas Samsung <strong>saw sales rise by a similar amount</strong>. By 2013, Samsung had became the market leader with <strong>sales reaching 450 million units</strong>.</p>
<p><strong>Details in P4</strong>:</p>
<p>Template:</p>
<p><strong>The other three</strong> top selling mobile phone brands between 2009 and 2013 were LG, ZTE and Apple. In 2009, these companies sold around 125 million, 50 million and 25 million mobile handsets <strong>respectively</strong>, but Apple <strong>overtook</strong> the other two vendors in 2011. In 2013, purchases of Apple handsets <strong>reached</strong> 150 million units, <strong>while</strong> LG <strong>saw declining sales and</strong> the figures for ZTE rose only <strong>slightly</strong>.</p>
<p>Review:</p>
<p>The other three top selling mobile phone brands between 2009 and 2013 were LG, ZTE and Apple. In 2009, these companies sold around 150 million, 50 million and 20 million mobile handsets respectively, but Apple overtook the other two vendors in 2011. In 2013, purchases of Apple handsets reached 150 million units, while LG saw declining sales and the figures for ZTE rose only slightly.</p>
<h2 id="vocabulary">Vocabulary</h2>
<ul>
<li>sold worldwide</li>
<li>sales figures, purchases</li>
<li>Most popular, best selling brand, top selling</li>
<li>second most succesful manufacturer</li>
<li>Market leader</li>
<li>mobile phones, handsets, units</li>
<li>brands, manufacturer, vendor, company</li>
<li>saw the biggest rises, saw declining sales</li>
<li>close to, almost, approximately, around</li>
<li>double the number of</li>
<li>rise by a similar amount</li>
<li>respectively</li>
<li>Overtook the other two vendors</li>
</ul>
]]></content>
      <categories>
        <category>IELTS</category>
      </categories>
      <tags>
        <tag>Writing</tag>
      </tags>
  </entry>
  <entry>
    <title>Writing Task 1: Description</title>
    <url>/2022/06/05/Writing-Task-1-Description/</url>
    <content><![CDATA[<p>no conclusion, but summary (overview)</p>
<p>a report, describing task</p>
<a id="more"></a>
<h2 id="summary">Summary</h2>
<p><strong>Question types</strong></p>
<ol type="1">
<li>Line graph</li>
<li>Bar chart</li>
<li>Pie chart</li>
<li>Table</li>
<li>Diagram-comparing</li>
<li>Diagram-process</li>
</ol>
<p>The first four types are most common, and they are almost the same: <strong>describe, compare, changes/trends</strong> numbers.</p>
<p><strong>Eassy Structure</strong></p>
<p>4 paragraphs</p>
<ol type="1">
<li><p><strong>Introduction</strong></p>
<p>1 sentence: paraphrase the question</p>
<p>just try to change key words, or order</p></li>
<li><p><strong>Overview</strong> (or put it at the end)</p>
<p>2 sentences: The main, general things</p></li>
<li><p><strong>Details</strong></p></li>
<li><p><strong>Details</strong></p>
<p>2 paragraphs makes you organize or group the information better</p></li>
</ol>
<p><strong>No conclusion!</strong></p>
]]></content>
      <categories>
        <category>IELTS</category>
      </categories>
      <tags>
        <tag>Writing</tag>
      </tags>
  </entry>
  <entry>
    <title>Writing Task 1: Line Graph</title>
    <url>/2022/06/05/Writing-Task-1-Line-Graph/</url>
    <content><![CDATA[<p>Line graphs show numbers changing over a period of time</p>
<p>A line graph always has 2,3,4,5 lines on a graph. And your job is to compare the lines, not decribe them sepratately.</p>
<a id="more"></a>
<h2 id="summary">Summary</h2>
<p><strong>First</strong>, make a very general comparison. (Overview)</p>
<p>Just like the blue line is the highest. Very very general</p>
<p><img src="overview.png" width="50%" height="50%"></p>
<p><strong>Second</strong>, compare the lines at specific points. (Details)</p>
<p>The yellow parts:</p>
<p><img src="detail.png" width="50%" height="50%"></p>
<h2 id="example">Example</h2>
<p><img src="example.png"></p>
<p><strong>Introduction</strong>: change the order and key words</p>
<p>The line graph compares the amount of electricity produced in France using 4 different sources of power over a period of 32 years.</p>
<p><strong>Overview</strong>: 2 sentences, 2 main points</p>
<p>It is clear that nuclear power was by far the most important means of electricity generation over the period shown. Renewables provided the lowest amount of electricity in each year.</p>
<p><strong>Details</strong>: 2 paragraghs, compare the lines</p>
<p><strong>Paragragh 3</strong>: comparison with the start</p>
<p>In 1980, thermal power stations were the main source of electricity in France, generating around 120 terawatt hours of power. Nuclear and hydroelectric power stations produced just under 75 terawatt hours of electricity each, and renewables provided a negligible amount. Just one year later, nuclear power overtook thermal power as the primary source of electricity.</p>
<p><strong>Tips when describing numbers</strong></p>
<p>Can’t write:</p>
<ul>
<li>Nuclear was 75 TW-h of electricity.</li>
<li>Nuclear produced 75 TW-h of electricity.</li>
</ul>
<p>Should write:</p>
<ul>
<li>Nuclear power was used to produce …</li>
<li>Nuclear power stations produced …</li>
</ul>
<p>Not just take words from graph, think more clearfully.</p>
<p><strong>Paragragh 4</strong>: describle tendency, peak</p>
<p>Between 1980 and 2005, electricity production from nuclear power rose dramatically to a peak of 430 terawatt hours. By contrast, the figure for thermal power fell to only 50 terawatt hours in 1985, and remained at this level for the rest of the period. Hydroelectric power generation remained relatively stable, at between 50 and 80 terawatt hours, for the whole 32-year period, but renewable electricity production saw only a small rise to approximately 25 terawatt hours by 2012.</p>
<h2 id="vocabulary">Vocabulary</h2>
<ul>
<li>amount of electricity produced</li>
<li>source of / provided / generating</li>
<li>means of electricity generation</li>
<li>over a period of / over the period shown</li>
<li>by far the most important</li>
<li>a negligible amount</li>
<li>nuclear power overtook thermal power</li>
<li>as the primary source of electricty</li>
<li>rose dramatically to a peak of</li>
<li>by contrast</li>
<li>the figure for nulcear power</li>
<li>remained at this level, remained relatively stable</li>
<li>saw only a small rise</li>
<li>approximately 25</li>
</ul>
]]></content>
      <categories>
        <category>IELTS</category>
      </categories>
      <tags>
        <tag>Writing</tag>
      </tags>
  </entry>
  <entry>
    <title>Writing Task 1: Pie Chart</title>
    <url>/2022/06/05/Writing-Task-1-Pie-Chart/</url>
    <content><![CDATA[<p>Pie charts can show numbers, but they always show percentages.</p>
<a id="more"></a>
<h2 id="example">Example</h2>
<p><img src="example.png"></p>
<p><strong>Introduction</strong>: paraphrase the question</p>
<p>Question:</p>
<p>The charts below show household spending patterns in two countries between 1980 and 2008.</p>
<p>Practice:</p>
<p>The pie charts compare five kinds of household expenses between UK and New Zealand in 1980 and 2008 respectively.</p>
<p>Template:</p>
<p>The pie charts compare five categories of household expenditure in the UK and New Zealand in the years 1980 and 2008.</p>
<p><strong>Overview</strong>: 2 sentences and 2 main points</p>
<ul>
<li><p>both countries similar tendency</p></li>
<li><p>biggest difference</p></li>
</ul>
<p>Practice:</p>
<p>It is noticeable that both countries saw declining spending on food and drink and saw slightly rises on utility bills from 1980 to 2008. Leisure costs were always the main part of household spending in UK, whereas the percentages of leisure spending in New Zealand were low in these two years.</p>
<p>Template:</p>
<p><strong>It is noticeable</strong> that the proportion of spending on food and drink <strong>fell</strong> in both countries <strong>over the 28-year period</strong>, while spending on utility bills <strong>rose</strong>. <strong>Also</strong>, UK residents spent <strong>a significantly larger percentage</strong> of their household <strong>budgets</strong> on leisure <strong>than their New Zealand counterparts.</strong></p>
<p>Review:</p>
<p>It is noticeable that the proportion of spending on food and drink fell in both countries over the 28-year period, while spending on utility bills rose. Also, UK residents spent a significantly larger percentage of their household budgets on leisure than their New Zealand counterparts.</p>
<p><strong>Details in P3</strong>: same information as the overview, but details with numbers</p>
<p>In 1980, <strong>29% of</strong> an average New Zealand household budget went on food and drink, <strong>while</strong> the equivalant figure for UK home was 23%. By 2008, expenditure on food and drink <strong>had fallen by 4%</strong> in New Zealand, <strong>and by a full 10% in the UK</strong>. By contrast, both countries <strong>saw an increase</strong> in expenditure on utility bills for the average home, <strong>from 27% to 31% in New Zealand and from 26% to 28% in the UK.</strong></p>
<p><strong>Details in P4</strong>:</p>
<p>Practice:</p>
<p>The proportion of spending on Leisure saw a significant rise from 27% to 34% over the 28-year period, whereas the equivalant figure for New Zealand residents only declined 1%. The household budget on transport and other categories in UK home and New Zealand home remained relatively stable between 1980 and 2008.</p>
<p>Template:</p>
<p>Leisure activities accounted for the highest proportion of UK household spending in both years, but only the third highest proportion in New Zealand. In fact, in 2008, Nea Zealanders spent on half as much in relative terms on recreation (17%) as UK residents (34%). In both countries, transport costs and other costs took roughly 15% and 10% of household budgets respectively.</p>
<p>Review:</p>
<p>Leisure activities <strong>accounted for the highest proportion</strong> of UK household expenditure in both years, <strong>but only the third highest proportion</strong> in New Zealand. In fact, in 2008, New Zealanders spent on <strong>half as much in relative terms on</strong> recreation (17%) <strong>as</strong> UK residents (34%). In both countries, transport costs and other costs took <strong>roughly</strong> 15% and 10% of household budgets respectively.</p>
<h2 id="tips">Tips:</h2>
<ul>
<li>Don’t describe each country separately</li>
<li>Don’t describe each year separately</li>
<li>Compare countries and years <strong>together</strong></li>
<li>Mention all 5 categories</li>
<li>Divide the categories into two groups for the two “detail” paragraphs</li>
<li>The category “Other” is not important</li>
<li>Don’t write “Leisure was 34%”</li>
<li>Write “Households spent 34% of their money on leisure”</li>
</ul>
<h2 id="vocabulary">Vocabulary:</h2>
<ul>
<li>spending, expenditure, spent, costs</li>
<li>proportion of spending</li>
<li>percentage of household budget</li>
<li>the equivalant figure for a UK home</li>
<li>fell, rose, saw an increase in</li>
<li>by 2008, expenditure had fallen</li>
<li>in 2008, expenditure fell</li>
<li>spent a significantly larger percentage</li>
<li>than their New Zealand counterparts (same groups people)</li>
<li>29% of an average household budget went on (goes on sth)</li>
<li>while, by contrast</li>
<li>leisure accounted for the highest proportion</li>
<li>spent half as much in relative terms (only percentage, so use relative)</li>
<li>recreation, leisure</li>
</ul>
]]></content>
      <categories>
        <category>IELTS</category>
      </categories>
      <tags>
        <tag>Writing</tag>
      </tags>
  </entry>
  <entry>
    <title>Contrastive Learning Survey(6) — Contrastive Learning with positive/negative sampling</title>
    <url>/2022/05/17/Contrastive-Learning-Survey-6-%E2%80%94-Contrastive-Learning-with-positive-negative-sampling/</url>
    <content><![CDATA[<p>In addition to the lack of high-level semantic representations, the sampling of positive and negative samples for instance discrimination tasks also has obvious problems. Positive samples are all from its own data augmentation, while negative samples are directly sampled from a large memory (within the same batch, memory bank or a momentum encoder). The problem with this is that negative samples may have positive sample, which they are the same class, but are different instances. Another problem is that hard negative samples and easy negative samples have the same weights in InfoNCE loss , which make model too simple if it focus on too many easy negative samples. In this chapter, we will see many interesting works with different methods on solving sampling problem in CL.</p>
<a id="more"></a>
<h2 id="what-should-not-be-contrastive-in-contrastive-learning">What Should Not Be Contrastive In Contrastive Learning</h2>
<p>Link: https://arxiv.org/abs/2008.05659</p>
<p><strong>Motivation: </strong></p>
<p><img src="LooC/motivation.png"></p>
<p>This paper proposed that data augmentation may hurt image representations, especially when they are used on downstream tasks. For example, representation vectors by color augmentation are used on a bird identification task , or representation vectors by rotation augmentation are used on a animal identifacation task.</p>
<p>Sounds reasonable, and it did!</p>
<p><strong>Result:</strong></p>
<p><img src="LooC/result.png" width="75%" height="75%"></p>
<p>Table 1 shows that add rotation augmentation on MoCo will significantly reduces its accuracy on IN-100(ImageNet-100) this dataset. And their model LooC has a better result.</p>
<p><strong>Method:</strong></p>
<p><img src="LooC/method.png"></p>
<p>And add all these <span class="math inline">\(Z\)</span> regions into loss function:</p>
<p><span class="math display">\[\mathcal{L}_{q}=-\frac{1}{n+1}\left(\log \frac{E_{0,0}^{+}}{E_{0,0}^{+}+\sum_{k^{-}} E_{0,0}^{-}}+\sum_{i=1}^{n} \log \frac{E_{i, i}^{+}}{\sum_{j=0}^{n} E_{i, j}^{+}+\sum_{k^{-}} E_{i, i}^{-}}\right)\]</span></p>
<p>where <span class="math inline">\(E_{i, j}^{\{+,-\}}=\exp \left(\boldsymbol{z}_{i}^{q} \cdot \boldsymbol{z}_{i}^{k_{j}^{\{+,-\}}} / \tau\right)\)</span></p>
<p><strong>Insights:</strong></p>
<p>I think the movitation is quite reasonable. But actually, I am not clear about the method and this paper do not provide pesudo code or open source code. I am not sure that if aggregating all different augmentation infomations into the same loss function will solve the problem of different specific downstream tasks. It's more like an improvement in robustness, rather than aiming at adapting with specific downstream tasks.</p>
<h2 id="boosting-contrastive-self-supervised-learning-with-false-negative-cancellation">Boosting Contrastive Self-Supervised Learning with False Negative Cancellation</h2>
<p>Link: https://arxiv.org/abs/2010.02037</p>
<p><strong>Motivation</strong>:</p>
<p>Negative samples by instance discrimination will contain many potential positive samples(images in the same class). And these false negative samples will hurt CL in 2 ways: <strong>discarding semantic information</strong> and <strong>slow convergence</strong></p>
<p><strong>Method</strong>:</p>
<p><img src="FPC/method.png"></p>
<p>There are 3 parts:</p>
<ol type="1">
<li>Traditional CL framework</li>
<li>False Negative Identification</li>
<li>False Negative Cancellation
<ol type="1">
<li>Elimination</li>
<li>Attraction</li>
</ol></li>
</ol>
<p>The first part is the model backbone. This paper use SimCLR and MoCo.</p>
<p>The second part is the method how to find those false negatives without label information.</p>
<p>The approach to identify false negatives based on the following observations:</p>
<ol type="1">
<li>False negatives are samples from different images with the same semantic content, therefore they should hold certain similarity (e.g., dog features).</li>
<li>A false negative may not be as similar to the anchor as it is to other augmentations of the same image, as each augmentation only holds a specific view of the object</li>
</ol>
<p>Based on above observations, the strategy follows as:</p>
<ol type="1">
<li>Create a support set contains the image itself, its original augmentation(put into model), and extra augmentations (to hold the second observation).</li>
<li>Each negative sample compute a similarity score set, e.g. a negative sample will have 8 similarity scores if the size of support set is 8. This paper use <strong>cosine similarity</strong>.</li>
<li>Using an aggregation method for the similarity score set, <strong>Maximum</strong> or <strong>Mean</strong></li>
<li>Selecting the most similar negative samples as false negative samples.
<ol type="1">
<li>Select <strong>top k</strong> high similarity samples</li>
<li>Select the samples those similarity score <strong>is greater than a threshold</strong></li>
</ol></li>
</ol>
<p>The third part is how to use these false negative samples. There are 2 approaches:</p>
<p><strong>False Negative Elimination</strong>: These false negatives do not contrast against them, which means drop them from the loss function.</p>
<p><strong>False Negative Attraction</strong>: These false negatives will be added into positive samples just like supervised contrastive learning’s loss function.</p>
<p><strong>Insights</strong>:</p>
<p>This paper gives many insights from their exhaustive experiments since it is from Google.</p>
<p><img src="FPC/elimination.png" width="75%" height="75%"></p>
<p>The Gap between FNE and baseline will be larger with the increasing random crop ratio. It is reasonable since larger crop ratio will lead to a higher ratio of false negatives.</p>
<p><img src="FPC/attraction.png" width="75%" height="75%"></p>
<p>The attraction strategy is much more sensitive to the quality of the found false negatives compared to the elimination strategy.</p>
<p>The paper has many other interesting findins and really recommend you to read paper.</p>
<h2 id="unsupervised-representation-learning-by-invariance-propagation">Unsupervised Representation Learning by Invariance Propagation</h2>
<p>Link: https://arxiv.org/abs/2010.11694</p>
<p><strong>Motivation:</strong></p>
<p>This paper also aims to solve the positive/negative sampling problem.</p>
<ol type="1">
<li>negative samples by random may have positive samples.</li>
<li>Positive samples also should have different levels. Easy positive samples and hard positive samples have the same impact on model now.</li>
</ol>
<p><strong>Method:</strong></p>
<p>This paper has a assumption that:</p>
<blockquote>
<p>If two points v1 and v2 in a high-density region are close, then their semantic information should be similar.</p>
</blockquote>
<p>Hence, we can use metric method like KNN to calculate anchors’ positive samples step by step.</p>
<p><img src="Invariance_Propagation/method.png"></p>
<p><strong>Strategy of Positive samples of an anchor image</strong>:</p>
<p>The process is illustrated in Fig 1. In each step, all k-nearest neighbors of the current discovered positive samples are added to the positive sample set. The process repeats l steps.</p>
<p>The difference between tradition KNN and their approach can be shown in the last step of Figure 1. Samples in the dashed circle are positive samples discovered by KNN. By comparison, in their approach, point B is included in K-nearest neighbors of point A and point C is not included.</p>
<p><strong>Hard Sampleing Strategy:</strong></p>
<p>The core is that this paper think positive samples which are already close to the anchor and negative samples which are already far away from the anchor are easy samples. They do not need to be optimized more. However, those positive samples that are far away in the positive sample set(C in Fig 1 )and the negative samples that are relatively close(B in Fig 1) are difficult samples that are more helpful to the model.</p>
<p>Strategy:</p>
<ol type="1">
<li><p>Select P samples with the lowest similarity to construct the hard positive sample set <span class="math inline">\(\mathcal{N}^{h}(i)\)</span>.</p>
<p>These hard positive samples deviate far from the anchor sample such that they provide more intra-class variations, which is beneficial to learn more abstract invariance.</p></li>
<li><p>Denote the M nearest neighbors of <span class="math inline">\(v_i\)</span> as <span class="math inline">\(\mathcal{N}_{M}(i)\)</span>, The <span class="math inline">\(M\)</span> is large enough such that <span class="math inline">\(\mathcal{N}(i) \subseteq \mathcal{N}_{M}(i)\)</span>. Then denote the hard negative sample set <span class="math inline">\(\mathcal{N}_{n e g}(i)=\mathcal{N}_{M}(i)-\mathcal{N}(i)\)</span>.</p></li>
</ol>
<p>Then the hard sample mining loss can be like:</p>
<p><span class="math display">\[\begin{aligned} \mathcal{L}_{i n v}\left(x_{i}\right) &amp;=-\log P_{v_{i}}\left(\mathcal{N}^{h}(i) \mid B(i)\right) \\ &amp;=-\log \frac{\sum_{p \in \mathcal{N}^{h}(i)} \exp \left(\bar{v}_{p} \cdot v_{i} / \tau\right)}{\sum_{n \in B(i)} \exp \left(\bar{v}_{n} \cdot v_{i} / \tau\right)} \end{aligned}\]</span></p>
<p>The overall loss function is just InfoNCE + hard sample mining loss, as follow:</p>
<p><span class="math display">\[\mathcal{L}\left(x_{i}\right)=\mathcal{L}_{i n s}\left(x_{i}\right)+\lambda_{i n v} \cdot \omega(t) \cdot \mathcal{L}_{i n v}\left(x_{i}\right)\]</span></p>
<p>where <span class="math inline">\(\omega(t)\)</span> as 0 is the first T epochs, because it is not reliable in frist <span class="math inline">\(t\)</span> epoches.</p>
<h2 id="contrastive-learning-with-hard-negative-samples">Contrastive Learning With Hard Negative Samples</h2>
<p>Link: https://arxiv.org/abs/2010.04592</p>
<p><strong>Motivation:</strong></p>
<p>This paper also focus on negative samples. In metric learning, some work proves that <strong>hard negative samples</strong> can help guide a learning method to correct its mistakes more quickly (Schroff et al., 2015; Song et al., 2016). Therefore, this paper also wants to use hard negative samples in contrastive learning. Compared with metric learning, contrasitive learning is a unsupervised task, so there are 2 challenges:</p>
<ol type="1">
<li>We do not have access to any true similarity of dissimilarity information.</li>
<li>We need an efficient sampling strategy for this tunable distribution.</li>
</ol>
<p>This paper use Figure 1 to show the defination of Hard Negatives.</p>
<p><img src="HNS/motivation.png"></p>
<p><strong>Method:</strong></p>
<blockquote>
<p>We begin by asking <em>what makes a good negative sample?</em></p>
<p>To answer this question we adopt the following two guiding principles:</p>
<p>Principle 1. q <em>should only sample “true negatives”</em> <span class="math inline">\(x_i\)</span> <em>whose labels differ from that of the anchor</em> x<em>.</em></p>
<p>Principle 2. <em>The most useful negative samples are ones that the embedding currently believes to be similar to the anchor.</em></p>
</blockquote>
<p>Because of no supervision, upholding Principle 1 is impossible to do exactly. This paper aims to upholds Principle 1 approximately, and simultaneously combines this idea with the key additional conceptual ingredient of “hardness” (encapsulated in Principle 2).</p>
<p>The theory of this article is very solid with lots of mathmatical prooves, which I want to skip them and only give the final loss pesudo code.</p>
<p><img src="HNS/loss.png"></p>
<p><strong>Insights:</strong></p>
<p>I think that the core of this paper is that they think negative samples those are not very close to and also are not too far from the anchor in the encoding space(called <strong>Hard negative samples</strong>) are useful for model to learn better representation.</p>
<p>Hence, I think it is similar with the previous paper: find those ture negative samples without prior knowledge, where the difference is on different statistics methods.</p>
<h2 id="hard-negative-mixing-for-contrastive-learning">Hard Negative Mixing for Contrastive Learning</h2>
<p>Link: https://arxiv.org/abs/2010.01028</p>
<h2 id="conditional-negative-sampling-for-contrastive-learning-of-visual-representations">Conditional Negative Sampling For Contrastive Learning of Visual Representations</h2>
<p>Link: https://arxiv.org/abs/2010.02037</p>
<h2 id="debiased-contrastive-learning">Debiased Contrastive Learning</h2>
<p>Link: https://arxiv.org/abs/2007.00224</p>
<h2 id="contrastive-crop">Contrastive Crop</h2>
<p>Link: https://arxiv.org/abs/2202.03278</p>
<p>Github: https://github.com/xyupeng/ContrastiveCrop</p>
<p><strong>Motivation:</strong></p>
<p>Random crop will hurt image and decrease image semantic.</p>
<p>A method for sampling true right positive samples.</p>
<p>提出了一种技术，</p>
<p>从图中可以发现，对比学习模型本身就可以捕捉物体大概的位置信息，从而来指导crops的选取。</p>
<p>利用这种特征提取物体边框，避免错误正样本对</p>
<p>中心抑制，上述方法由于其带来了更小的选取范围，生成具有较高相似度的样本对的可能性也提高了</p>
<p>降低crops集中在图片中心的概率，从而增大采样的方差。</p>
<h2 id="conclusion">Conclusion</h2>
<p>So far, we have seen a lot of works on how to sample more accurate and better quality positive/negative samples without labels.</p>
<ol type="1">
<li><p>Use similarity metrics by images’ embedding vectors to get more reliable samples based on the assumption that same class embedding will be close/similar in the hyperplane.</p></li>
<li><p>Restrict data augmentations to achieve more reliable samples by Contrastive Crop or LooC.</p></li>
</ol>
<p>So can we combine these 2 ideas that using similarity metrics of the anchor and its augs to sort positive samples with data augmentations as true positive samples and low similarity augs as true negative samples even they are augmentations from the same image.</p>
]]></content>
      <categories>
        <category>Contrastive Learning</category>
      </categories>
      <tags>
        <tag>self-supervised learning</tag>
        <tag>computer vision</tag>
      </tags>
  </entry>
  <entry>
    <title>DATA7202 多元线性回归</title>
    <url>/2020/02/29/DATA7202-1st-Week-Review/</url>
    <content><![CDATA[<p>UQ 2020 Semester 1 DATA7202 <em>Statistical Methods for Data Science</em></p>
<p>多元线性回归复习笔记（不一定对），省略了很多证明，我能咋办，我也看不懂呀</p>
<p>好文：</p>
<p>https://zhuanlan.zhihu.com/p/25436791</p>
<p>https://www.cnblogs.com/nxld/p/6435677.html</p>
<p>https://zhuanlan.zhihu.com/p/48541799（几乎所有数学证明可以找到）</p>
<a id="more"></a>
<h1 id="离散和连续">离散和连续</h1>
<p>如果随机变量的值可以都可以逐个列举出来，则为离散型随机变量。如果随机变量X的取值无法逐个列举则为连续型变量。</p>
<h1 id="极大似然估计mle">极大似然估计（MLE）</h1>
<h2 id="似然">似然</h2>
<p>假如我们抛硬币100次，有80次朝上的，我们猜测抛硬币结果朝上的概率为80%。</p>
<p>这就是<strong>似然</strong>！ 我们通过<strong>事实</strong>，来反推测出这个<strong>事件</strong>的各种参数。（抛硬币是概率，也可以是均值，可以是方差等等）</p>
<p>计算一个事件的概率需要<strong>参数</strong>和<strong>数据</strong></p>
<p>比如一个事件的数据是<span class="math inline">\((x_1,…, x_n)\)</span>, 它的参数是<span class="math inline">\((\theta_1,…,\theta_k)\)</span>:</p>
<p>它的<strong>概率函数</strong>表示为 <span class="math inline">\(f\left(x_1,…,x_{i} ; \theta_{1}, \dots, \theta_{k}\right)\)</span>, 也表示为<span class="math inline">\(f\left(x_1,…,x_{i} {｜} \theta_{1}, \dots, \theta_{k}\right)\)</span>,</p>
<p>此时参数已知，数据未知，当你知道了数据，你就可以计算出概率。</p>
<p>它的<strong>似然函数</strong>表示为 <span class="math inline">\(L_{n}\left(\theta_{1}, \ldots, \theta_{k} ; x_{1}, \ldots, x_{n}\right)\)</span></p>
<p>此时数据已知，参数未知。</p>
<p>它们的公式相等都表示，都是计算出事件发生概率的公式。</p>
<h2 id="mle">MLE</h2>
<p>极大似然估计的理念就是选取最有可能的似然！</p>
<p>翻译一下就是求出<span class="math inline">\(L_{n}\left(\theta_{1}, \ldots, \theta_{k} ; x_{1}, \ldots, x_{n}\right)\)</span> 每个参数<span class="math inline">\(\theta\)</span> 的最大值！</p>
<p>最大的参数值的意义代表着最有可能是这个事件的真实参数！</p>
<p>怎么求呢？</p>
<p>极大似然估计首先假设事件结果每一次都是<strong>独立</strong>的。</p>
<p>根据独立性质，<span class="math inline">\(f\left(x_1,…,x_{i} {｜} \theta_{1}, \dots, \theta_{k}\right) = \prod_{i=1}^{n} f\left(x_{i} ; \theta_{1}, \ldots, \theta_{k}\right)\)</span></p>
<p><span class="math inline">\(\prod\)</span> 表示连乘号，例如：$_{i=1}^{n} x_i = x_1 x_2 … x_n $</p>
<p>因此我们有了极大似然估计的公式：</p>
<p>$L_{n}(<em>{1}, , </em>{k} ; x_{1}, , x_{n}) = <em>{i=1}^{n} f(x</em>{i} ; <em>{1}, , </em>{k}) $</p>
<h2 id="例子抛硬币">例子（抛硬币）</h2>
<p>抛10枚硬币，记录出现正面的次数。</p>
<p>假如出现正面的次数为4.</p>
<p>计算概率：</p>
<p>即求 <span class="math inline">\(f(4|\theta)\)</span></p>
<p>根据二项分布定理，<span class="math inline">\(f(x|\theta) = \binom {10}{4} \theta^4 (1-\theta)^6\)</span></p>
<p>我们要求它的最大值：</p>
<ol type="1">
<li>求导：</li>
</ol>
<p>对<span class="math inline">\(theta\)</span>求导</p>
<p>$ =  (4<sup>3(1-)</sup>6-6<sup>4(1-)</sup>5)$</p>
<ol start="2" type="1">
<li><p>令其等于0</p>
<p>$4(1-)-6= 0 $</p>
<p><span class="math inline">\(\theta = 0.4\)</span></p></li>
</ol>
<p>假设我们不知道投硬币的概率，从抛10次得到4次是正面的结果来看，潜意识也会认为是40%。</p>
<h2 id="例子正态分布">例子（正态分布）</h2>
<p>用极大似然估计证明正态分布的参数<span class="math inline">\(\mu，\sigma^2\)</span> 是平均值和方差。</p>
<p><span class="math inline">\(f\left(x ; \mu, \sigma^{2}\right)=\frac{1}{\sqrt{2 \pi \sigma^{2}}} e^{-\frac{(x-\mu)^{2}}{2 \sigma^{2}}}\)</span></p>
<p>手算或者网上好多，再打一遍latex有点多。</p>
<p>证明无偏和有偏的我还不懂</p>
<h1 id="多元线性回归">多元线性回归</h1>
<p><img src="/images/data7202_1st_3.jpg"></p>
<p>p是coefficent的数量，即<span class="math inline">\(\Beta\)</span>的数量，n是有多少条数据，即<span class="math inline">\(X\)</span>矩阵的行数。</p>
<p>以后再举例子，我睿了。</p>
<h2 id="推导">推导</h2>
<p><span class="math inline">\(\boldsymbol{Y}=\boldsymbol{X} \boldsymbol{\beta}+\boldsymbol{\varepsilon}\)</span></p>
<p>根据最小二乘法，极大似然估计或者error function都能计算出 <span class="math inline">\(\boldsymbol{\beta}\)</span>：<span class="math inline">\(\left(X^{\top} X\right)^{-1} X^{\top} Y\)</span></p>
<p>我们的预测值为：<span class="math inline">\(\widehat{Y}=X \widehat{\boldsymbol{\beta}} = X\left(X^{\top} X\right)^{-1} X^{\top} Y\)</span></p>
<p>称<span class="math inline">\(X\left(X^{\top} X\right)^{-1} X^{\top}\)</span> 为<strong>hat matrix</strong>，或<strong>H</strong></p>
<h2 id="h-matrix">H matrix</h2>
<p><span class="math inline">\(H = X\left(X^{\top} X\right)^{-1} X^{\top}\)</span></p>
<p><span class="math inline">\(H\)</span> 是一个对称和idempotent（幂等）矩阵</p>
<p>一个矩阵A是idempotent的意思为 <span class="math inline">\(A^2 = A\)</span></p>
<p>证明H是idempotent的：</p>
<p><span class="math inline">\(H^2 = X\left(X^{\top} X\right)^{-1} X^{\top} (X\left(X^{\top} X\right)^{-1} X^{\top}) = X(X^{\top} X^{-1} (X^{\top} X))X^{\top} X^{-1} X^{\top}\)</span></p>
<p>因为 <span class="math inline">\(X^{\top} X^{-1} (X^{\top} X) = I\)</span></p>
<p>即 $ H^2 = H$</p>
<p>证明<span class="math inline">\(H\)</span>是对称的：</p>
<p>还不会，网上都说显然可知。。。</p>
<p>##残差</p>
<p>残差residual为：<span class="math inline">\(e = Y-\widehat{Y}=\left(1_{n}-H\right) Y\)</span></p>
<p>证明：<span class="math inline">\(\operatorname{Var}(\mathrm{e})=\left(\mathrm{I}_{n}-\mathrm{H}\right)[\operatorname{Var}(\mathrm{Y})]\left(\mathrm{I}_{n}-\mathrm{H}\right)^{\top}=\sigma^{2}\left(\mathrm{I}_{n}-\mathrm{H}\right)\)</span></p>
<p>令<span class="math inline">\(\mathrm{I}_{n}-\mathrm{H} = A\)</span></p>
<p>$() = E((A(Y-))(A(Y-))^T) $</p>
<p><span class="math inline">\(= E(A(Y-\mu)(Y- \mu)^TA^T)\)</span></p>
<p><span class="math inline">\(= AE((Y-\mu)(Y- \mu)^T)A^T\)</span></p>
<p><span class="math inline">\(= A\operatorname{Var}(\mathrm{Y})A^T\)</span></p>
<p><span class="math inline">\(= (\mathrm{I}_{n}-\mathrm{H})\operatorname{Var}(\mathrm{Y})(\mathrm{I}_{n}-\mathrm{H})^T\)</span></p>
<p>因为<span class="math inline">\((\mathrm{I}_{n}-\mathrm{H})(\mathrm{I}_{n}-\mathrm{H})^T = (\mathrm{I}_{n}-\mathrm{H})\)</span> （根据对称，转置等于本身。再根据幂等，平方等于本身）</p>
<p><span class="math inline">\(= \sigma^2(\mathrm{I}_{n}-\mathrm{H})\)</span></p>
<p>因此<span class="math inline">\(e_{i}=\sigma^{2}\left(1-h_{i i}\right)\)</span> ,<span class="math inline">\(h_{ii}\)</span> 是<span class="math inline">\(H\)</span> 的对角元，也叫<strong>杠杆值（leverage）</strong></p>
<h2 id="leverage杠杆值">leverage杠杆值</h2>
<p><span class="math inline">\(h_{ii}\)</span> 为<span class="math inline">\(H\)</span>矩阵对角线上的值，它能很大的影响预测值，原因如图：</p>
<p><img src="/images/data7202_1st_8.jpg"></p>
<p>由于<span class="math inline">\(\sum_{i=1}^{n} h_{i i}=p\)</span>（好像是根据trace，对称幂等矩阵公式推导的，我睿了）：</p>
<p>因此如果<span class="math inline">\(h_{ii} &gt; 2p/n\)</span>, 则称观测值<span class="math inline">\(x_i\)</span> 为异常值。</p>
<p><img src="/images/data7202_1st_6.jpg"></p>
<p>如果Studentized residual的绝对值非常大，例如<span class="math inline">\(\left|r_{i}^{*}\right|&gt;2\)</span> ，也可以说<span class="math inline">\(x_i\)</span>是异常值。</p>
<h2 id="model-assumption">Model assumption</h2>
<p>残差对于model assumption很重要，它必须满足下面四条性质。</p>
<h3 id="normalityqq-plot">Normality(QQ-PLOT)</h3>
<p>残差的分布应该接近正态分布（均值为0）</p>
<p>可以使用qq-plot来判断数据集是否服从正态分布，当qqplot的图近似为一条45度的直线时，则说明该数据服从正态分布。</p>
<p><img src="/images/data7202_1st_3.jpg"></p>
<p>上图左半部分近似正态分布，因此qqplot为一条45度直线。而右半分布则不是。</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">qqnorm(x)</span><br><span class="line">qqline(x)</span><br></pre></td></tr></table></figure>
<h3 id="linearity">Linearity</h3>
<p>模型应该捕获所有系统数据中存在的方差，只留下随机噪声。</p>
<p>或者说作出的图像近似一条直线。说明可以和我们假设是线性相关一致。</p>
<p>###homoscedasticity(constant variance)</p>
<p>假设我们有家庭收入和奢侈品支出的数据。使用二元回归，我们使用家庭收入来预测奢侈品消费。不出所料，收入与支出之间有很强的积极联系。通过检查残差，我们发现了一个问题–残差对于家庭收入较低的值很小（几乎所有低收入家庭在奢侈品上的花费都不多），而较富裕家庭的残差大小却存在很大差异（有些家庭在奢侈品上花了很多钱，而有些家庭的奢侈品花销则比较中等）。这种情况表示异方差性，因为误差的大小随自变量的值而变化。</p>
<p>如图所示：</p>
<p><img src="/images/data7202_1st_1.jpg"></p>
<p>我们发现上述例子就可以对应“nonconstant variance”图，即方差和残差之间存在关联性。</p>
<p>“contant variance“ 图残差对于自变量或者预测值都没有关联性，说明就是随机误差，是我们想要的结果。</p>
<p>直接测试符不符合homoscedasticity的代码为</p>
<p><img src="/images/data7202_1st_4.jpg"></p>
<p><strong>suggested power transformation</strong> 的用处：</p>
<p>suggested power transformation值为<span class="math inline">\(p\)</span>, <span class="math inline">\(Y^{p}\)</span>更能满足homoscedasticity性。（<span class="math inline">\(Y\)</span> 就是真实值）</p>
<p>例子：suggested power transformation值为0.5，那么使用 <span class="math inline">\(Y^{0.5}\)</span> 比使用<span class="math inline">\(Y\)</span> 更能满足homoscedasticity性，此时残差<span class="math inline">\(e = Y^{0.5}-\widehat{Y}\)</span></p>
<h3 id="independence">independence</h3>
<p><img src="/images/data7202_1st_2.jpg"></p>
<p>如果残差根据时间并没有明显线性关系时，说明残差具有独立性。</p>
<p>时间的意思是自变量输入的顺序。</p>
<h1 id="具体操作例子">具体操作例子</h1>
<p>数据：中风患者出院后康复情况</p>
<p>应变量（<span class="math inline">\(Y\)</span>): 康复出院时的步行速度</p>
<p>有120组数据，17个自变量属性。</p>
<p>目的：</p>
<ol type="1">
<li>尝试预测出院时的步行速度</li>
<li>找出哪些自变量最能影响预测值</li>
</ol>
<p>变量的含义就不介绍了</p>
<h2 id="变量处理">变量处理</h2>
<p>对于分类型变量，一般我们将其处理为dummy variables（哑变量）</p>
<p>只有2个分类时，例如性别：我们将female = 1， male = 0</p>
<p>分类数量大于2时，例如例子中的（side of stroke）变量含有“left”，“right”，“other”三个分类</p>
<p>将其变为：“left” = (1 0 0), “right” = (0 1 0), “other” = (0 0 1)</p>
<p>实际上我们可以将3类的进行优化，例如：“left” = (1 0), “right” = (0 1), “other” = (0 0)</p>
<p>既不是left也不是right的自然就是另一个分类。</p>
<p>这样做的目的可以减少空间。</p>
<h2 id="第一步线性检查linearity">第一步：线性检查（linearity）</h2>
<p>我们对所有变量画一次单变量-因变量散点图，观察其是否具有线性。</p>
<p>因为具有线性才能符合我们的假设，我们的公式。</p>
<h2 id="第二步相关性">第二步：相关性</h2>
<p>为什么属性可以影响到因变量（行走速度）呢？</p>
<p>它可能是相关的，但是相关并不意味着因果关系。 这些变量中有许多相互关联，因为其他因素（例如，运动功能受损的程度）以相似的方式影响其中一个以上的因素。</p>
<p>我们仍然希望看到似乎与出院步行速度直接相关的解释变量会成为多元回归分析中的最佳预测变量。</p>
<h2 id="第三步缺失数据">第三步：缺失数据</h2>
<p>在120组数据中只有85组拥有完整的所有变量。</p>
<p>然而大多数的多元线性回归会直接去掉含有未知量的数据组。</p>
<p>这大大缩小了样本大小。鼓励我们尽可能使用较少的解释变量。</p>
<h3 id="对解释变量的初始剔除">对解释变量的初始剔除</h3>
<p>对每一个解释变量都做一次简单线性回归，仅保留那些显著关联响应变量的解释变量。</p>
<p>通过这个操作，我们删除了“FIM cognitive”，“MAS 6-8“，“age”，“gender”，“side of stroke”等变量。</p>
<h2 id="第四步线性回归">第四步：线性回归</h2>
<p>对解释变量 &quot;FIM motor score” 和“ walking speed at admission”分别做简单线性回归，如下：</p>
<p><img src="/images/data7202_1st_7.jpg"></p>
<h3 id="p-value">p-value</h3>
<p>当p-value小于给定<span class="math inline">\(\alpha\)</span>, 一般为0.005或0.001时，则称该变量是否有意义。（越小越好）</p>
<p>具体一点：</p>
<p>零假设：对于<span class="math inline">\(x_j\)</span>, <span class="math inline">\(\beta_j = 0\)</span> 含义就是<span class="math inline">\(x_j\)</span>这个解释变量对于响应变量毫无影响。</p>
<p>备择假设：<span class="math inline">\(\beta_j \neq 0\)</span></p>
<p>如何计算？</p>
<p>我们计算<span class="math inline">\(\hat{\mathrm{y}}=\mathrm{b}_{0}+\mathrm{b}_{1} \mathrm{x}_{1}+\mathrm{b}_{2} \mathrm{x}_{2}+\ldots+\mathrm{b}_{\mathrm{d}} \mathrm{x}_{\mathrm{d}}\)</span> (排除掉<span class="math inline">\(\mathrm{b}_{j}\)</span>)，比较这个值产生的error和包括<span class="math inline">\(\mathrm{b}_{j}\)</span>时的error。</p>
<p>当小于某个阈值（<span class="math inline">\(\alpha\)</span>）时，则说明<span class="math inline">\(x_j\)</span>是一个重要的解释变量。</p>
<p>多元线性回归中一个解释变量的p值通常会比简单线性回归中此变量的p值高（说明更少的重要性）</p>
<p>甚至可能从“重要”被偏移到“不重要”</p>
<p>为什么呢？</p>
<p>因为选择其他的变量的时候就可能已经帮助到响应变量了，所以仅仅增加一个并不能很有效的帮助。</p>
<p>因此：仅有一些解释变量是重要的。</p>
<p>我们可以根据p-value值进行排序，讲较大的p-value对应的解释变量剔除。</p>
<h3 id="coefficient">Coefficient</h3>
<p>“Coef.“即是<span class="math inline">\(\beta\)</span>的值，越大说明对结果影响越大。（越大越好）</p>
<p>###R-squared</p>
<p>https://zhuanlan.zhihu.com/p/47180789</p>
<h4 id="sstosse">SSTO,SSE</h4>
<p><span class="math inline">\(SSTO = \sum_{i=1}^{n}\left(y_{i}-\bar{y}\right)^{2}\)</span></p>
<p><span class="math inline">\(y_i\)</span>是真实值，<span class="math inline">\(\bar{y}\)</span>是样本均值。</p>
<p><span class="math inline">\(\mathrm{SSE}=\sum_{i=1}^{n}\left(y_{i}-\hat{y}_{i}\right)^{2}\)</span></p>
<p><span class="math inline">\(\hat{y}_{i}\)</span>是<span class="math inline">\(y\)</span>的预测值。</p>
<p><img src="/images/data7202_1st_11.jpg"></p>
<p>从图中看出：</p>
<p>每个散点就是<span class="math inline">\(y\)</span>。</p>
<p>绿线就是<span class="math inline">\(\bar{y}\)</span>,因为是常数，所以是一条水平的直线。</p>
<p>红线是<span class="math inline">\(\hat{y}_{i}\)</span>,是由线性回归得出的直线。</p>
<p>所以SSTO是真实情况对于平均值的离散程度，而SSE是真实情况对于随机误差的离散情况（可能是个病句）</p>
<p>由这个两个值我们得到一个重要的判断值：</p>
<p><span class="math inline">\(R^{2}=\frac{\mathrm{SSTO}-\mathrm{SSE}}{\mathrm{SSTO}} = 1 - \frac{\mathrm{SSE}}{\mathrm{SSTO}}\)</span></p>
<p>当<span class="math inline">\(R^2\)</span>越接近1，说明回归线更加的精确。</p>
<p>由于这个是有偏估计，把它变为无偏后的<span class="math inline">\(R^2\)</span>就是“Adj R_squared”，道理以后再搞懂。</p>
<p>“Adj R_squared” = 0.8，则说明了解释变量解释了80%的响应变量的方差。（越大越好）</p>
<h2 id="多元线性回归的条件">多元线性回归的条件</h2>
<ol type="1">
<li>每一个解释变量和响应变量的关系都逼近一条直线（linearity）</li>
<li>没有高影响的异常值</li>
<li>残差逼近正态分布</li>
<li>残差具有constant varianve（用过 residuals vs fitted values图）</li>
<li>数据值独立</li>
<li>解释变量的个数p受到样本大小n的约束，通常我们根据经验法则：<span class="math inline">\(p \leq n/3\)</span></li>
</ol>
<h2 id="多元线性回归图">多元线性回归图</h2>
<p><img src="/images/data7202_1st_9.jpg"></p>
<p>通常我们使用p-value进行排序（越小越重要），如果p-value值相同，则使用t-test结果的绝对值（越大越重要）</p>
<p><img src="/images/data7202_1st_10.jpg"></p>
<p>我们还可以查看所有变量之间的correlation。我们发现有些变量之间也有很强的关联性，这并不好，大多数的做法是去掉它们。</p>
<h2 id="总结">总结</h2>
<ol type="1">
<li>如果需要，可以通过图形，相关性计算以及简单的线性回归与响应进行探索性数据分析，以找出有希望的变量。但是，这不能完全预期多元线性回归的结果。</li>
<li>估计的斜率系数可以解释为与解释变量的单位增加相关的响应变量的平均变化，而其他解释变量则保持不变。应该报告其置信区间。</li>
<li>找到关联后，因果关系通常仍然不清楚，但可能存在于变量对之间。这可以激励旨在改善反应变量结果的后续干预研究。</li>
<li>基于多个解释变量，可以使用多元线性回归为感兴趣的响应变量开发预测方程。</li>
<li>它还可以量化哪些解释变量与响应变量显着相关。</li>
<li>分类变量可以变为哑变量放入模型中</li>
<li>多重线性回归的假设与简单线性回归的假设相同，但对可能的解释变量的数量有额外的限制，建议最多为n / 3，其中n为观察数。</li>
</ol>
]]></content>
      <categories>
        <category>DATA7202</category>
      </categories>
      <tags>
        <tag>MLE</tag>
        <tag>stats</tag>
        <tag>biased estimate</tag>
      </tags>
  </entry>
  <entry>
    <title>Data Mining Notes</title>
    <url>/2019/11/29/Data_Mining_Notes/</url>
    <content><![CDATA[<p>关于数据挖掘的一些知识，内容包括分类，聚类，异常值检测，关联性分析等等。</p>
<p>大量截图和思路来自 the University of Queensland 的Dr Hongzhi Yin所教课程INFS7203 Data Mining。</p>
<a id="more"></a>
<h2 id="i.-classification-分类">I. Classification 分类</h2>
<h3 id="模型评估model-evluation">1.模型评估（model evluation）</h3>
<h4 id="混淆矩阵confusion-matrix">混淆矩阵（confusion matrix）</h4>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">Prediction/actual</th>
<th>T</th>
<th style="text-align: left;">F</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">T</td>
<td>True positive(TP)</td>
<td style="text-align: left;">False positive(FP)</td>
</tr>
<tr class="even">
<td style="text-align: left;">F</td>
<td>False negative(FN)</td>
<td style="text-align: left;">True negative(TN)</td>
</tr>
</tbody>
</table>
<p><strong>课件中的ppt：真实值是行，预测值是列。</strong></p>
<p>在我上网查资料或者很多流行的混淆矩阵的包里面都是我上述的真实值是列， 预测值是行。当时就默认是课件里的情况，所以在计算中会出现问题，并且经常有想要验算的想法。所以这里用和课件中想反的情况，提醒大家这都是取决于自己的。</p>
<h4 id="评估方法">评估方法</h4>
<ol type="1">
<li><p>$Accuracy =  $</p>
<p>很直观，预测成功的数量除以预测的总数</p>
<p>但是有<del>一个</del>几个不好的地方。我们很多时候只关注T和F中的一个。</p></li>
<li><p><span class="math inline">\(Precision = \frac {TP}{TP + FP}\)</span></p></li>
<li><p><span class="math inline">\(Recall = \frac{TP}{TP+FN}\)</span></p></li>
<li><p><span class="math inline">\(F1-value = 2\frac{Precision*Recall}{Rrecision+recall}\)</span></p></li>
</ol>
<p>最爱的举例环节：</p>
<p>小明有一天终于进入了心心念念的相亲角（有100个女生等着他）。由男人的三大错觉（分类器）他觉得<del>自己玉树临风，风趣幽默，才华横溢</del>, 预测会被99个女生有好感，1一个没有好感，然而事实是如此的残酷，相亲是如此的激烈，真实情况100个女生都没有相中小明。于是我们产生了一个混淆矩阵：</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">Prediction/actual</th>
<th>T</th>
<th>F</th>
<th>Total prediction</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">T</td>
<td>0</td>
<td>99</td>
<td>99</td>
</tr>
<tr class="even">
<td style="text-align: left;">F</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Total actual</td>
<td>0</td>
<td>100</td>
<td></td>
</tr>
</tbody>
</table>
<p>我们可以算出<span class="math inline">\(accuracy = \frac{1}{100} = 0.01\)</span>, 果然“男人的自我感觉”这个分类器非常的糟糕。</p>
<p>小明在这次无情的现实打脸后，强迫着被爸妈再次带到了相亲角。根据上次的经验，卑微的小明这次也觉得没有人会看上他，预测没有女生相中自己。然而这次事实上有一个女生不知道是不是圣母爆发，觉得小明太卑微了，给了他一次机会。 于是我们产生了一个混淆矩阵：</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">Prediction/actual</th>
<th>T</th>
<th>F</th>
<th>Total prediction</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">T</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td style="text-align: left;">F</td>
<td>1</td>
<td>99</td>
<td>100</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Total actual</td>
<td>1</td>
<td>99</td>
<td></td>
</tr>
</tbody>
</table>
<p>这次<span class="math inline">\(accuracy = \frac {99}{100} = 0.99\)</span>。 哇喔，小明顿时好佩服自己，居然有<span class="math inline">\(99%\)</span>的预测成功率预测成功自己不会被人看上。 等等，为什么<strong>预测重心变成了自己不成功的概率了</strong>，不是应该更希望自己被相中的嘛，让不成功的概率这么高干嘛🤣。</p>
<p>3年后，小明终于走出了上一次相亲的阴影<del>（等新的女生刷新太不容易了）</del>，再次走进相亲角。经过了人生的沉淀，小明明白他不需要关注那些看不上自己的女人<del>（气急败坏）</del>, 而要把重点放在那些看上自己的女生们。这次小明预测自己有20个女生对他有好感，80个没有。事实情况是有10个女生看中小明，90个没有。更重要的是撞大运了，那10个女生刚好也是小明预测应该喜欢他的。于是我们又有了混淆矩阵：</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">Prediction/actual</th>
<th>T</th>
<th>F</th>
<th>Total prediction</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">T</td>
<td>10</td>
<td>10</td>
<td>20</td>
</tr>
<tr class="even">
<td style="text-align: left;">F</td>
<td>0</td>
<td>80</td>
<td>80</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Total actual</td>
<td>10</td>
<td>9</td>
<td></td>
</tr>
</tbody>
</table>
<p>此时<span class="math inline">\(accuracy = \frac{10+80}{100} = 0.9\)</span>,当然这也充其量只能证明小明对自己有比较清醒的认知（<del>丑</del>) ,和他的目标（脱单）没什么关系的。 但是三年中小明学会了第二种度量方法<span class="math inline">\(Precesion = \frac{10}{10+10}=0.5\)</span>, 这说明小明以后预测谁谁谁喜欢自己，都能有50%的成功率！（卧槽，为什么要高兴，本来不就是成功和失败2个选项吗？？）。</p>
<p><span class="math inline">\(Recall = \frac {10}{0+10} = 100\%\)</span>, 这说明喜欢小明的妹子100%都被小明预测中了（呵，女人）。</p>
<p>现在的小明要是回到了三年前，他预测有99个妹子喜欢他，就会有45个妹子真的喜欢（Precision=0.5），而且小明对她们索然无味，都没有出乎他意料外的妹子（recall = 1）。小明想：我果然还是那个我，玉树临风，风趣幽默，才华横溢。醒醒现在的你已经不会说这样的话了，因为你已经是一个成熟的分类器（Classification)了。</p>
<h4 id="总结">总结</h4>
<p>如果嫌上面的例子篇幅过大，直接到PPT的week2-P43 背公式。</p>
<p>应付完了考试后，如果想加深理解，为什么要有新的度量方式而不是很容易理解的accuracy，可以google或者复习小明的悲惨经历。</p>
<p>上述的遭遇也是这一章<strong>Classification 分类</strong>的一个具体演示。小明基于他的数据（身高体重颜值兴趣背景等）有了一个对自己的认知（分类器）。当小明经过了一次相亲角的真实遭遇后（混淆矩阵评估），他验证了自己的认知对不对（这个分类器的好坏）。如果他对自己的认知非常的高，他就知道了他是哪种妹子的菜，他以后看到这种类型的妹子就知道他们很可能发生什么故事。</p>
<p>杠精提问：那你这个<strong>认知（分类器）</strong>哪里来的啊，你一开始的认知（玉树临风，风趣幽默，才华横溢）不是错的吗？这三年小明是怎么提升自己的啊（怎么改进分类器）？</p>
<p>“<font size="2">承认我优秀那么难吗，下一节就告诉你啦，每天100个俯卧撑100个仰卧起坐…….变秃</font>”</p>
<h3 id="分类方法">2. 分类方法</h3>
<h4 id="rote-learner-最原始最土味">1. Rote-learner (最原始最土味)</h4>
<p>当你要预测的数据和训练集里有的数据一模一样的时候，预测结果就是训练集中数据的标签。</p>
<h4 id="knnk近邻">2. KNN（K近邻）</h4>
<ol type="1">
<li><p>你先选一个K，比如5</p></li>
<li>你每次要预测一个数据的时候，就找离这个数据最近的5个训练集里面的点。</li>
<li><p>投票这5个点的分类。哪种分类占的多你预测的这个数据就属于这种分类。</p></li>
</ol>
<p>怎么定义距离？ 欧几里得距离（误差的平方和开根号）或者公式 <span class="math inline">\(\boldsymbol{d i s t}=\sqrt{\sum_{\boldsymbol{k}=1}^{\boldsymbol{n}}\left(\boldsymbol{p}_{\boldsymbol{k}}-\boldsymbol{q}_{\boldsymbol{k}}\right)^{2}}\)</span></p>
<p>p 和 q 是数据，一般我们的数据都是多维的，例如数据：庄笑齐（男，高，富，帅），每一个相同的列相减等到误差，误差平方和，开根号 ——&gt; 距离</p>
<p>KNN的缺点：</p>
<ol type="1">
<li><p>如何定义这个k值，如果k很小，我们的判断容易被噪声（noise）影响，如果k太大，可能包含更多其他的分类</p></li>
<li><p>KNN需要scale，因为数据的大小值非常影响knn的判断。</p>
<p>举例环节：我们现在的数据集拥有<strong>（年龄，收入）</strong> 2个属性，和一个标签<strong>（职业）</strong></p>
<p>现在我们有2个样本，一位程序员（25，10000）和一位医生（50，15000），现在我们要预测一位30岁拥有14000月薪的人的职业。</p>
<p>取k=1，根据公式<span class="math inline">\(d(x,程序员)=\sqrt{(25-30)^2+(10000-14000)^2} = 4000\)</span>,<span class="math inline">\(d(x,医生)=\sqrt{(50-30)^2+(15000-14000)^2} = 1000\)</span>, 由于距离医生更近，我们判断这人是一位医生。</p>
<p>然而事实上我们觉得他应该是一个程序员，因为更加的年轻。然而<strong>年龄</strong>在这个距离的公式里贡献的非常小，因为年龄和收入它们的<strong>纬度（定义域）</strong>不一样，所以在KNN中，我们经常需要预先进行scale操作，保证数据都在同一个度量标准中。</p>
<p>经过scale（根据比例压缩进0到1之间），我们现在的数据是：程序员（0.5，0.66），医生（1，1），</p>
<p>x（0.66.0.93）。（这个scale方法是我瞎XX想当然的）</p>
<p><span class="math inline">\(d(x,程序员)=\sqrt{(0.5-0.66)^2+(0.66-0.93)^2} = 0.31\)</span>,</p>
<p><span class="math inline">\(d(x,医生)=\sqrt{(1-0.66)^2+(1-0.93)^2} = 0.35\)</span>,</p>
<p>现在x就被预测为程序员了。</p></li>
<li><p>KNN不需要预先训练一个模型（lazy），每次预测一个数据，都要重新计算一边所有数据点的距离去找最近的，时间复杂度很大。</p></li>
</ol>
<h4 id="naïve-bayes朴素贝叶斯">3. Naïve Bayes（朴素贝叶斯)</h4>
<p>目标：我们有一组数据A，希望用这一组数据A判断它属于哪个类</p>
<p>核心思路：计算在给定这组数据的情况下它属于各个类的概率，概率最高的就把它判定为这个类。</p>
<p>​ 属于类C的概率就等于：<span class="math inline">\(P(C|A)\)</span></p>
<p>我们知道 <span class="math inline">\(P(C|A)=\frac{P(A|C)P(C)}{P(A)}\)</span></p>
<p>我们现在有什么：<span class="math inline">\(P(A_i|C)\)</span>:对于类C，每一种属性的概率。P(C):这个类在所有类里面的概率，P(A): 所有的<span class="math inline">\(P(C_i|A)\)</span>都是一样的，我们只比较大小的，可以忽略掉，比如要比<span class="math inline">\(\frac{5}{10000}\)</span>和<span class="math inline">\(\frac{5}{10000}\)</span>的大小不需要关心<span class="math inline">\(10000\)</span>.</p>
<p>缺点：为什么把这个分类方法的缺点提前就是朴素贝叶斯的最大bug，没有这个缺点进行不下去计算。我们怎么能从<span class="math inline">\(P(A_i|C)\)</span>来得出<span class="math inline">\(P(A|C)\)</span>呢？ 我们知道互相独立的事件的联合概率就等于各自的概率的乘积，所以我们朴素贝叶斯就假设所有属性是独立的？？？</p>
<p>有了这个假设后，我们的目标就变成了求出</p>
<p><span class="math display">\[\Pi P\left(A_{i} | C_{j}\right) \times P\left(C_{j}\right)\]</span>的最大值。</p>
<p>课件，tutorial，谷歌里的例子都非常的详细，我就不贴了，理解过程就好。</p>
<p>其他缺点：在对连续性变量操作的时候要提前把它们离散化，不然针对一个数据的概率会非常的少，效果也不好。</p>
<p>改进：</p>
<p>当我们做<span class="math inline">\(\Pi P\left(A_{i} | C_{j}\right) \times P\left(C_{j}\right)\)</span>这一步的时候，经常是很多很小很小的概率（0.0几）相称，值会越来越小，从而可能导致失去精确度（因为计算机算不了小数位很长的值，会四射五入）。</p>
<p>这时候我们就给它们取个<span class="math inline">\(log\)</span>变成<span class="math inline">\(\sum \log P\left(A_{i} | C_{j}\right)+\log P\left(C_{j}\right)\)</span>.</p>
<p><span class="math inline">\(\Pi P\left(A_{i} | C_{j}\right) \times P\left(C_{j}\right)\)</span>如果这个项目里有一项的概率是0，那就全为0了，是不对的。所以我们会加一个特别特别小的值，让概率避免成为0。</p>
<p>例如有一个对于收入的分类，标签为“低”，“中等”，“高”。 但是我们数据集里没有收入为“低”<span class="math inline">\(\Rightarrow P(C=“低”)=0\)</span>.</p>
<p>总共有1000个数据，我们就可以把<span class="math inline">\(P(C=“低”) = 0+1 / 1003\)</span>, 1003是因为在“中等”和“高”里也要加1。</p>
<h4 id="决策树">4.决策树</h4>
<h5 id="概念">概念</h5>
<p>下图是一个决策树的例子</p>
<p><img src="image-20191106221733796.png"></p>
<p>决策树易于理解，就是根据你的输入值一层一层的筛选出最后的Class。</p>
<p>杠精提问：那你是怎么选这个<strong>属性</strong>（右图黄色部分）作为分割的呀？那<strong>分割的条件</strong>又是怎么确定的呢？对于连续型的变量（Income），你是怎么找到选取80K作为临界值的呢？又是什么时候结束决策树的呢？（一定要全部的attribute全部分割过后吗？</p>
<ol type="1">
<li><p>Nominal Attributes:</p>
<p>可以有多维的分割和二元的分割</p>
<p><img src="image-20191106223823835.png"></p></li>
<li><p>Ordinal Attributes:</p>
<p>多元的形式直接把所有情况分开，而二元的形式必须要注意属性里存在的顺序。</p>
<p><img src="image-20191106223928930.png"></p></li>
<li><p>Continuous Attributes</p></li>
</ol>
<p><img src="image-20191106224342530.png"></p>
<p>怎么样的分割才算好呢？ 如果我们总共有20条记录，用一个分割条件后，各得到10条属性。这十条属性的类都刚好属于它们原来的类，即预测100%，纯净度purity也是100。我们定义一个测量的尺度叫做impurity（不纯度）</p>
<p>由此我们有了3种方法来计算impurity</p>
<h5 id="gini-index">1. Gini Index</h5>
<p>选取一个属性P，计算这个属性的GINI值 GINI(P)</p>
<p>将P分割成多个子节点后，计算每个的GINI值，在各自乘以它们的权重（weights)得到GINI(M)</p>
<p>计算 Gain = GINI(P) -GINI(M)</p>
<p>最高的Gain就是最好的分割</p>
<p>具体例子：</p>
<ol type="1">
<li><p>对于二元分类问题的计算</p>
<p><img src="image-20191106230226860.png"></p></li>
<li><p>对于多元属性的计算</p>
<p><img src="image-20191106230416524.png"></p></li>
<li><p>对于连续型属性的计算</p>
<p><img src="image-20191106230444301.png"></p></li>
<li>将所有的value进行排序（图中的sorted values）</li>
<li>将sorted values两两之间计算平均值作为split position（即分割的条件）</li>
<li>将问题化为二元分类问题进行GINI INDEX计算</li>
<li><p>找到最小的GINI的就是最小的impurity</p></li>
</ol>
<h5 id="entropy">2. Entropy</h5>
<p><span class="math inline">\(\text { Entropy }(t)=-\sum p(j | t) \log p(j | t)\)</span></p>
<p><span class="math inline">\(\sum p(j | t)\)</span> is the relative frequency of class j at node t.</p>
<p><span class="math inline">\(G A I N_{\text {rut }}=\text { Entropy }(p)-\left(\sum_{i=1}^{k} \frac{n_{i}}{n} \text { Entropy }(i)\right)\)</span></p>
<p>可以看成和GINI INDEX一样，只是计算的公式变了。</p>
<p>然而以上2种方法都有一个问题：Node impurity measures tend to prefer splits that result in large number of partitions, each being small but pure</p>
<p>计算纯净度的方法倾向于有大量分割的属性，例如如果对ID进行计算，它的纯净度就是1因为没有不同的。</p>
<p><img src="image-20191106232014439.png"></p>
<p>但是这并没有实际意义，如果我们将customer ID分割的话。因此我们有一个新的度量标准：</p>
<ol type="1">
<li>计算<span class="math inline">\(\text { SplitINFO }=-\sum_{i=1}^{k} \frac{n_{i}}{n} \log \frac{n_{i}}{n}\)</span> 可以当作<span class="math inline">\(\frac{n_{i}}{n}\)</span>的entropy</li>
<li>计算<span class="math inline">\(\operatorname{Gain} R A T I O_{\text {stat }}=\frac{G A I N_{\text {sut}}}{\text {SplitINFO}}\)</span> , 选GainRATIO最高的</li>
</ol>
<h5 id="error">3. Error</h5>
<p><span class="math inline">\(\text {Error }(t)=1-\max P(i | t)\)</span></p>
<h5 id="什么时候终止分割">什么时候终止分割？</h5>
<ol type="1">
<li>当这个节点只剩下了一种class</li>
<li>当这个节点里的tuple都是一样的（无法分割了）</li>
<li>early termination（提前结束避免过度拟合overfitting）</li>
</ol>
<h5 id="overfitting的坏处">Overfitting的坏处</h5>
<ol type="1">
<li>太多的分支导致noise可能也成为了分割的条件导致错误。</li>
<li>对于未知的样本，准确性很差：因为它对于已知数据集的拟合效果太高了。</li>
</ol>
<p>避免overfitting的方法：</p>
<p>early termination</p>
<ol type="1">
<li>结束当剩余的数据不满足用户自己定于的阈值时</li>
<li>结束当在扩展节点后却不提升impurity</li>
</ol>
<h5 id="优缺点">优缺点</h5>
<p>优点：</p>
<ol type="1">
<li>易于理解，模型的可解释性</li>
<li>易于构建</li>
<li>得益于已经训练出了模型，做分类十分迅速</li>
<li>对noise有鲁棒性（抗噪声，前提是overfitting要做的好）</li>
<li>容易处理冗余或无关的属性</li>
</ol>
<p>缺点：</p>
<ol type="1">
<li>决策树要占据的space要求非常大（使用贪婪算法一般不能够找到最优树）</li>
<li>没有考虑属性之间可能存在影响</li>
<li>每次只单独使用一个attribute做分割</li>
</ol>
<h5 id="例题如何从零开始构建一个数据库">例题：如何从零开始构建一个数据库</h5>
<p><img src="image-20191107094244109.png"></p>
<ol type="1">
<li>计算每个attributes各种分割可能性的GINI，找到最低的GINI值（就是最高的GAIN）（找出分割的条件）</li>
<li>比较每个attributes最低的GINI值，找到最低的GINI值，即是第一步的分割属性</li>
<li>查看第一步分割后的表格，重复1，2，直到前面提到的决策树终止条件</li>
</ol>
<h2 id="ii.similarity相似度">II.Similarity（相似度）</h2>
<p>相似度该怎么度量呢？</p>
<p>对于nominal的，非常简单，非0即1</p>
<p>对于有顺序的ordinal，<span class="math inline">\(Dissimilarity = ｜x-y｜/(n-1)\)</span> (values mapped to 0 to n-1, n is the number of values).</p>
<p>例如对于收入(low, medium, high)， 可以map变成(0,1,2), <span class="math inline">\(dissimilarity(low, high) = |0-2|/2 = 1\)</span></p>
<p>对于连续型的随机变量，有3种measure的方法，<strong>当含有多个变量时，必须先做normalization（scale）</strong></p>
<h3 id="曼哈顿距离aka-city-block-taxicab-l_1norm-manhattan-distance">1. 曼哈顿距离（aka &quot;City block”, taxicab, <span class="math inline">\(L_1\)</span>norm , Manhattan distance)</h3>
<p>$ d(x,y) = _{k=1}^{n}| x_k-y_k|$</p>
<h3 id="欧几里得距离euclidean-distanceaka-l_2-norm">2. 欧几里得距离（Euclidean distance，aka <span class="math inline">\(L_2\)</span> norm）</h3>
<p>$ d(x,y) = $</p>
<h3 id="supermumaka-l_maxnorm-l_inftynorm">3. Supermum(aka <span class="math inline">\(L_{max}\)</span>norm, <span class="math inline">\(L_{\infty}\)</span>norm)</h3>
<p><span class="math inline">\(d(x,y) = max(|x_k -y_k|)\)</span></p>
<p>例子：</p>
<p><img src="image-20191107101011006.png"></p>
<h3 id="二元属性的相似性">二元属性的相似性</h3>
<p><img src="image-20191107102524476.png"></p>
<p>例子：</p>
<p><img src="image-20191107102555880.png"></p>
<p>为什么要用Jaccard，是因为很多时候我们<strong>只关注都是1的情况</strong>。</p>
<p>例如在一个超市的用户和物品表格中，1表示该用户买了这类物品，0表示没买：</p>
<p><img src="image-20191107102734670.png"></p>
<p>很容易想到，0将会有非常多，1很少，所以使用SMC会给我们错误的信息。</p>
<h3 id="cosine-similarity">Cosine Similarity</h3>
<p>将每一条tuple变成一个向量vector，计算2个向量间的夹角</p>
<p><span class="math inline">\(\cos \left(p_{\nu}, p_{2}\right)=\left(p_{t} \bullet p_{2}\right) /\left\|p_{t}\right\|\left\|p_{2}\right\|\)</span></p>
<p><img src="image-20191107103215716.png"></p>
<p>应用：</p>
<p><img src="image-20191107103330975.png"></p>
<p>例如我们想查看2个文档是否相似。我们找出几个关键单词在这几个文档中出现的频数。做成上图的表格。</p>
<p>我们计算每个document的cosine similarity就能计算出2个文档间的相似度。</p>
<h2 id="iii.-clustering-聚类">III. Clustering 聚类</h2>
<hr>
<h3 id="概念-1">1.概念</h3>
<p>聚类和分类的区别就是没有标签了。</p>
<p>举例环节：</p>
<p>有很多种聚类的形式：</p>
<ol type="1">
<li><p>Partitional Clustering(分区聚类)：类和类之间是没有交集的。例如常见的k-means。</p>
<p><img src="image-20191016195923119.png"></p></li>
<li><p>Hierarchical Clustering(分层聚类)：一个类是可以包含其他类的。例如我属于数据科学专业，数据科学专业属于工程学院，工程学院属于大学。<del>我属于帅哥，帅哥属于男的</del></p>
<p><img src="image-20191016195859318.png"></p></li>
<li><p>Soft Clustering(软聚类?)：一个数据(object)可以属于多个类，和第二种聚类方式的区别在于，类之间有交集但是也有不属于对方的部分。 <span class="math inline">\(A \cap B \neq \emptyset\)</span> and $A B A  or  B $.</p>
<p><img src="image-20191016195732039.png"></p></li>
</ol>
<h3 id="k-means">2. K-means</h3>
<p>核心思想：</p>
<p>每个类都有一个类中心(centroid)，数据集里面点到各个类中心的距离最短的那个类就是这个点的类。</p>
<p>杠精提问：咋找这个类中心呀，既然聚类本身就是不知道有什么类的情况下才使用的方法，你还能整出来一个类的中心点？</p>
<p>具体步骤：</p>
<ol type="1">
<li>先要确定一个K，K代表了我们想要有多少类，K=5那最后我们就能分出五类来。</li>
<li>随机选择K个初始点，把它们当作就是5个类的类中心。</li>
<li>计算每个点到各个类中心的距离，把离它们最近的点加入它们，这样我们就有了有5个充满了数据集的类。</li>
<li>计算现在类的中心点（平均值）</li>
<li>回到第3步。</li>
<li>直到点们都不在类之间移动，中心点不变，或者很少进行移动了就停止迭代，结束。</li>
</ol>
<p>评估：</p>
<p>像分类一样，聚类也可以用方法评估（不是很准，因为就根本没人知道正确答案）。</p>
<p>我们想象中一个类应该是它们越像，这个类别越准确。因为k-means是用距离来定义这个“像”的，我们也可以用距离来评估。</p>
<p>我们称这个指标为SSE：<span class="math inline">\(S S E=\hat{\mathbf{a}}^{K} \underset{|c| c}{\hat{\mathbf{a}}} \operatorname{dist}^{2}\left(c_{i}, x\right)\)</span></p>
<p>别慌，其实就是类里面的所有点到类中心的距离的平方和，这就代表了这个类内部聚不聚拢，把数据集里面所有的类的这个值加起来，就代表了这个分类方法的分类效果。每个类当然是越聚拢越好，所以SSE值也是越低越好。</p>
<p>最优K值：</p>
<p>如何选择K？前面我们说了随便选，但是设想一下，对于一个应该只有2类的问题（生与死），我们给它分五类，那这是不合理不科学的。虽然我们不知道正确答案，但是还是有方法可以判断一下的。</p>
<p>我们尝试很多很多K，从K=2运行到K=10？20？一遍，分别计算各自K的SSE，会有一张如下类似的图</p>
<p><img src="image-20191016212820651.png"></p>
<p>最佳的K值就是图中这样的拐点（经过它之后SSE的变化不明显了）</p>
<p>初始点选择：</p>
<p>初始点的选择是会影响K-means的结果的！所以我们决定用2种方法优化一下初始点错误。</p>
<ol type="1">
<li>Multiple runs. 多跑几次，多随机选择几次。</li>
<li>每次run一开始选超过K个的初始点，然后选择这些里面距离最远的（most widely separated）</li>
</ol>
<p>后期处理：</p>
<ol type="1">
<li>可以删掉很小的cluster（可能代表了异常值）</li>
<li>分散宽松的cluster（内部SSE很大的类）</li>
<li>合并接近的cluster（内部SSE很小的类）</li>
</ol>
<p>K-means难以解决的问题：</p>
<ol type="1">
<li>每个类拥有不同的大小</li>
</ol>
<p><img src="image-20191017145039838.png"></p>
<p>K-means算法只要求点到类中心点距离最短，但会忽略类本身的大小不同。</p>
<ol start="2" type="1">
<li>每个类的密度不一样</li>
</ol>
<p><img src="image-20191017145213113.png"></p>
<ol start="3" type="1">
<li>每个类的形状不一样</li>
</ol>
<p><img src="image-20191017145248703.png"></p>
<h3 id="hierarchical-clustering分层聚类">3. Hierarchical Clustering（分层聚类）</h3>
<h4 id="概念-2">概念</h4>
<p><img src="image-20191016195859318.png"></p>
<p>我们发现现实生活中有很多的分类都会包含下面更加细分的类，所以就研究出了分层聚类。</p>
<p>我们有2种分层聚类的方法，一种是自下而上(agglomerative)的，一种是自上而下的(divisive)。</p>
<p><img src="image-20191017151143939.png"></p>
<p>这张图表明了这2种方法的具体步骤。</p>
<h4 id="agglomerative-方法">agglomerative 方法</h4>
<p>思路：</p>
<ol type="1">
<li>agglomarative是自下而上的，我们得从每一个数据点开始，合并最接近的2个数据点。</li>
<li>将合并成功的数据点变成一个类</li>
<li>计算这个类与其他的类的距离</li>
<li>重复1，2，3，直到最后只剩下一个类（即全体都被包含了）</li>
</ol>
<p>杠精笑齐：步骤1里面什么叫最接近？步骤3里面的距离怎么算？</p>
<p>例子：</p>
<p>我们有左图中这样的数据分布：</p>
<p><img src="image-20191107104418581.png"></p>
<ol type="1">
<li><p>我们先计算每个点之间的距离（这里我们采用[曼哈顿距离](#1. 曼哈顿距离（aka &quot;City block&quot;, taxicab, <span class="math inline">\(L_1\)</span>norm , Manhattan distance)）,结果为右上图</p></li>
<li><p>合并<strong>距离最近</strong>的两个点，图中我们得到<span class="math inline">\(d(42,43) = 1\)</span> 是最近的2个点，合并它们</p></li>
<li><p>我们得到了一个新的距离矩阵:</p>
<p><img src="image-20191107104735380.png"></p>
<p>有了一个新的问题，我们知道42，43分别对其他点的距离，但是我们怎么<strong>计算(42,43)这个新的类到其他点的距离</strong>呢？ 也就是图中的黄色部分是怎么计算的呢？</p></li>
</ol>
<p>当我们知道计算这个距离后，我们只需要继续重复合并最近的2个点（类），直到只有一类结束。</p>
<p>我们有很多种计算合并后的新类与其他类的距离计算方式。</p>
<ol type="1">
<li><p>MIN:</p>
<p><img src="image-20191107105318615.png"></p>
<p>我们选取新类所有点到其他类中所有点中最短的距离，作为距离</p>
<p>例如在我们的例子中我们就用了MIN方法：</p>
<p><img src="image-20191107110531148.png"></p>
<p>我们计算(42,43)新类对类(18)的距离：</p>
<p>我们计算d(42,18) = 24, d(43,18) = 25, 我们使用MIN为距离即(42,43)类对(18)的距离为24.</p>
<p>以此类推得到(42,43)对所有其他类的距离。</p>
<p><img src="image-20191107105452108.png"></p>
<p>接下来重复步骤1，步骤2，找到距离最小的两个类为d(25,27) = 2，合并它们在计算(25,27)对其他类的距离。一直重复到只有一个类。具体步骤为：</p>
<p><img src="image-20191107111021167.png"></p>
<p>我们得到最后的dendogram为：</p>
<p><img src="image-20191107111103027.png"></p>
<p>你想要分几类就在这个树图里切一刀，例如你想要有2个类，就把<span class="math inline">\(C_5\)</span>切了，就把数据分为了<span class="math inline">\((C_4,C_1)\)</span>两类。</p>
<p><strong>后面的各种方法都类似MIN</strong></p></li>
<li><p>MAX:</p>
<p>把用最小的距离变成用最长的距离：</p>
<p><img src="image-20191107111351503.png"></p></li>
<li><p>Group Average:</p>
<p>距离变成计算所有点到点的距离的平均值：</p>
<p><img src="image-20191107111529510.png"></p></li>
<li><p>Centroid:</p>
<p>计算每个类的类中心，距离为2个类中心的距离：</p>
<p><img src="image-20191107111600986.png"></p></li>
</ol>
<h5 id="limitation-of-min">Limitation of MIN:</h5>
<ol type="1">
<li><p>对noise很敏感：</p>
<p>只用一个值</p></li>
<li><p>产生链接现象(chaining phenomenon):</p>
<p>两个本来很远，一定不属于同一类的点p，q，但是它们之间有很多点，这样p每次最近的点都是p，q连线之间的点，最后会导致p和q分到了同一类。</p></li>
</ol>
<h5 id="limitation-of-max">Limitation of MAX:</h5>
<p><img src="image-20191107113748190.png"></p>
<p>很难对大小不同的类进行分类。</p>
<p>但是MAX方法抗噪声和异常值的效果很好，所以一般编程软件关于分层聚类的参数默认都用MAX方法。</p>
<h4 id="divisive-方法">divisive 方法</h4>
<h5 id="构建最小扫描树minimum-spanning-tree">构建最小扫描树（Minimum Spanning Tree）</h5>
<p><img src="image-20191107114517311.png"></p>
<p>如图，首先找距离最近的两个点连线，接下来找最近的(p,q)连线，其中p是在已经连线的点中，q是没有被连线的点。找到q后将q和p连线。重复过程。</p>
<p>当你完成了Minimum Spanning Tree后，你减掉最后几次连成的线，就是完成分类（根据你要有多少个类）</p>
<h3 id="density-based-clustering">4. Density-based clustering</h3>
<p>基于密度的聚类经常用在我们的数据在局部区域有很高的密度时</p>
<p>例如：</p>
<p><img src="image-20191107115105917.png"></p>
<h4 id="dbscan">DBSCAN</h4>
<p>DBSCAN就是针对以上情况的算法。</p>
<p>首先我们有2个自己定义的值：</p>
<ol type="1">
<li><p>EPS: 以点为圆心，以EPS为半径做圆，圆内其他数据点的个数我们就称为密度。</p></li>
<li><p>MinPts：当圆内的点个数（密度）超过了MinPts时（包含点本身），我们称这个点是core point</p>
<p>​ 如果这个点密度没有超过MinPts，但是它在core point附近，称为Border point</p>
<p>​ 或者说Border point的EPS里会有core point点出现。</p>
<p>​ 如果这个点既不是core point也不是border point，就称为noise point</p></li>
</ol>
<p>例子：</p>
<p><img src="image-20191107120016766.png"></p>
<p>具体聚类步骤：</p>
<ol type="1">
<li>将所有点贴上core，border，noise point的标签</li>
<li>删除noise point</li>
<li>将在EPS范围内的所有core points连上线</li>
<li>每一个完成连线的core points组即作为一类</li>
<li>将每个border point分配给任意它临近的core point的那一类</li>
</ol>
<p>例子：</p>
<p><img src="image-20191107120304306.png"></p>
<h4 id="dbscan的缺点">DBSCAN的缺点</h4>
<p>DBSCAN处理不了具有不同的密度的类（一个类里面有多种密度）。它只能区分高密度的类和低密度的类，但是处理不了密度都相同，但其实是不同的类的情况。需要有一点的背景知识才能使用。</p>
<h4 id="如何选取eps和minpts">如何选取EPS和MinPts</h4>
<ol type="1">
<li>选取一个k，计算k-distance，即点到离它最近的第K个点的距离</li>
<li>对这些k-distance进行升序排序</li>
<li>plot画图如下</li>
</ol>
<p><img src="image-20191107125740790.png"></p>
<p>纵坐标为排序的k-distance，横坐标为点的数量。</p>
<p>我们在图中可以找到一个sharp change（图中k-distance = 10）的时候，</p>
<p>我们就选这个k-distance(10)为EPS，k(4)为MinPts。</p>
<p>一般根据经验，k都选4</p>
<h3 id="cluster-validity">5. Cluster Validity</h3>
<p>对于classification，我们有accuracy，recall，precision等评估方式。</p>
<p>那对于Cluster我们能有什么呢？</p>
<p>首先我们知道这是很困难的，因为我们并没有正确答案，我们自己都不知道数据集的标签。当一种分类算法给数据上标签后，自然而然我们也不知道它是对的还是错的。</p>
<p>但是我们还是要寻找一些可能的方法的，用这些方法可以帮我们来判断：</p>
<ol type="1">
<li>这么多聚类方法，哪个比较好，该用哪个？</li>
<li>类和类之间的信息</li>
<li>类内部的信息</li>
<li>避免噪声异常值之类的干扰</li>
</ol>
<p>根据不同的聚类算法，我们可以得出完全不同的分类。例如：</p>
<p><img src="image-20191107130848744.png"></p>
<p>下面介绍几种不同的方式：</p>
<h4 id="groud-truth">1. Groud Truth</h4>
<p>Groud Truth是这个数据集真实的标签。</p>
<p>非常的扯淡，因为我们都知道真实的标签还干嘛要用聚类方法。</p>
<p>不过这个方法可以帮助我们验证我们聚类算法，当发现了一种新的聚类算法的时候，可以在已知数据集上进行，并用Groud Truth来判断。</p>
<p>方法也特别的简单。</p>
<p>groud truth： 真实的标签/类为$ P = {P_1,…,P_s}$</p>
<p>聚类方法得出的标签/类为 <span class="math inline">\(C = \{C_1,…,C_t\}\)</span></p>
<p><img src="image-20191107131546291.png"></p>
<p><img src="image-20191107131602994.png"></p>
<p>例子：</p>
<p><img src="image-20191107132455283.png"></p>
<ol start="2" type="1">
<li>Purity</li>
</ol>
<p><img src="image-20191107134314241.png"></p>
<h4 id="internal-measure">2. Internal Measure</h4>
<p>只使用数据集自身的信息来判断。</p>
<ol type="1">
<li>Cohesion：类的聚拢程度</li>
<li>Separation：类和类之间的离散程度</li>
</ol>
<h5 id="sse和bss">SSE和BSS</h5>
<p>计算cohesion的方法类似于之前提到的SSE：</p>
<p><span class="math inline">\(S S E=W S S=\sum_{i} \sum_{x \in C_{i}}\left(x-m_{i}\right)^{2}\)</span></p>
<p>计算separation用WSS：</p>
<p><span class="math inline">\(\begin{aligned} B S S &amp;=\sum_{i}\left|C_{i}\right|\left(m-m_{i}\right)^{2} \\-&amp; \text { Where }|C| \text { is the size of cluster } i \end{aligned}\)</span></p>
<p>例子：</p>
<p><img src="image-20191107135247397.png"></p>
<h5 id="silhouette-coefficient">Silhouette Coefficient：</h5>
<p>这种方法既考虑了cohesion也考虑了separation</p>
<p><img src="image-20191107135420153.png"></p>
<p>a是i点到它类内其他点的平均距离（cohesion）</p>
<p>b是离i最近的类的所有点的平均距离（separation）</p>
<h5 id="correlation-with-distance-matrix">Correlation with Distance Matrix</h5>
<p>计算2个矩阵：</p>
<ol type="1">
<li>distance matrix（每个数据的距离）</li>
<li>incidence matrix（每个数据是否属于同一类）</li>
</ol>
<p>计算公式为：</p>
<p><span class="math inline">\(r=\frac{\sum_{i=1, j=1}^{n}\left(d_{i j}-\bar{d}\right)\left(c_{i j}-\bar{c}\right)}{\sqrt{\sum_{i=1, j=1}^{n}\left(d_{i j}-\bar{d}\right)^{2}} \sqrt{\sum_{i=1, j=1}^{n}\left(c_{i j}-\bar{c}\right)^{2}}}\)</span></p>
<p>d是distance matrix，c是incidence matrix</p>
<p>|r| 越高代表聚类效果越好。 （只考虑绝对值）</p>
<p>下图是用k-means对2个数据集做聚类后，求出的correlation值</p>
<p><img src="image-20191107140059885.png"></p>
<p>|Corr|越大，效果越好。</p>
<h4 id="statistical-framework-for-sse">3. Statistical Framework for SSE</h4>
<p>当我们想要评估一个聚类方法的时候，我们可以把这个方法用在目标数据集和很多个随机生成的数据集中。</p>
<p>分别计算它们的SSE。</p>
<p>当我们发现，目标数据集的SSE和随机数据集的SSE非常的不同时，我们就能知道这个聚类方式对目标数据集是有效的（即它只对目标数据集效果好，而不是随便什么数据集都是效果好的）。</p>
<h2 id="iv.-association-rule-关联性分析">IV. Association Rule 关联性分析</h2>
<hr>
<p>目的：发现事物之间有趣的规则。</p>
<p>要是我们学会了这个，可以做广告推荐。</p>
<p>例如你逛超市的时候看一个东西，比如牛奶，如果我们知道<strong>购买牛奶的人有很高概率买面包</strong>，那超市在牛奶旁边就在面包，消费者很有可能直接顺手拿了。</p>
<p>而如何计算这个概率，了解对象之间的关联性分析，就是此章的内容。</p>
<p>定义notation：</p>
<p>一个association rule可以表示为 $ X Y$</p>
<p>前面的例子可以显示为 <span class="math inline">\(牛奶 \rightarrow 面包\)</span></p>
<h3 id="measures">1. Measures</h3>
<h4 id="support">1. Support</h4>
<p>Rule: $ X Y$</p>
<p>有2种support的算法，第一种是计算基数（频数）</p>
<p><span class="math inline">\(Support( X \rightarrow Y) = | X \cup Y|\)</span></p>
<p>第二种是计算概率</p>
<p><span class="math inline">\(Support( X \rightarrow Y) = P（X \cup Y）\)</span></p>
<p>例子：</p>
<p>我们有一个集合为{milk, coke, pepsi, beer, juice}</p>
<p>我们的阈值设定为当support &gt; 3 时，判断这个rule是frequent</p>
<p><span class="math inline">\(B_1 = \{m, c, b\}, B_2 = \{m, p, j\}, B_3 = \{m, b\}, B_4 = \{c, j\}, B_5 = \{m, p, b\}, B_6 = \{m, c, b, j\}, B_7 = \{c, b, j\}, B_8 = \{b, c\}\)</span></p>
<p><span class="math inline">\(S(m \rightarrow b) = 4, S(b \rightarrow c)= 4 , S(c \rightarrow j) =3\)</span></p>
<p>Support 并不关心顺序，上面的反过来也行。</p>
<h4 id="confidence">2. Confidence</h4>
<p><span class="math inline">\(\text { Confidence }(\mathrm{X} \rightarrow \mathrm{Y})=\mathrm{P}(\mathrm{Y} | \mathrm{X})=\mathrm{P}(\mathrm{X} \cup \mathrm{Y}) / \mathrm{P}(\mathrm{X})\)</span></p>
<p>根据定义我们知道：</p>
<p><span class="math inline">\(\text { Support }(\mathrm{X} \rightarrow \mathrm{Y}) = \text { Support }(\mathrm{Y} \rightarrow \mathrm{X})\)</span></p>
<p><span class="math inline">\(\text { Confidence }(\mathrm{X} \rightarrow \mathrm{Y}) \neq \text { Confidence }(\mathrm{Y} \rightarrow \mathrm{X})\)</span></p>
<p>找到一个我们认为有关联的关系需要同时超过我们给定的support阈值和confidence阈值。</p>
<h3 id="apriori-algorithm">2. Apriori Algorithm</h3>
<p>对于一个超级大的数据集，对每个item和它们的组合分别求出support和confidence来找出关联性信息是基本不可能的（计算量太大）。</p>
<p>首先我们发现对于一个组合<span class="math inline">\(\{X,Y,Z,…,\}\)</span>, 它的support都是相等的而无关<span class="math inline">\((\rightarrow)\)</span>。但是confidence是不同的。</p>
<p>由此我们发现，计算support非常的快（比confidence快），所以我们可以先找满足support的item，再在这个item里找满足confidence的关系。</p>
<p>超市里面有商品{A,B,C,D,E}，则它们所有可以的item组合为如下：</p>
<p><img src="image-20191107151133433.png"></p>
<p>Apriori定理：如果一个item不是frequent的，它的所有子集subitems都不是frequent的。</p>
<p><img src="image-20191107152732396.png"></p>
<p>如图当你计算出AB不是frequent后，不用在计算任何包含AB的item了，大大的减少了计算量。</p>
<p>算法过程：</p>
<ol type="1">
<li>计算单个item的support</li>
<li>剔除低于阈值support的item，保留满足条件的单个item</li>
<li>生成包含2个对象的item，计算support，剔除不满足的，保留满足的</li>
<li>继续生产，计算，删除，保留</li>
</ol>
<p>例子：</p>
<p><img src="image-20191107155311317.png"></p>
<p>C是生成的可能item，L是所有满足minsup的item组合。</p>
<p>所有的L就是我们要找的满足minsup的item。</p>
<p>问题是怎么生产C呢？</p>
<p>分2步：</p>
<ol type="1">
<li>self-join <span class="math inline">\(L_k\)</span></li>
<li>pruning</li>
</ol>
<p>self-join的例子:</p>
<p>上图的<span class="math inline">\(L_2 = \{ AC,BC,BE,CE\}\)</span></p>
<p>第一步：<span class="math inline">\(L_2 \ join\  L_2 = {ABC,ABE,ACE,BCE}\)</span></p>
<p>第二步：ABE 会被删掉因为 AE不在<span class="math inline">\(L_2\)</span>里面，根据Apriori算法，AE不是frequent，它的子类必不frequent。因此ABE会被删掉。</p>
<p>因此我们得到<span class="math inline">\(C_3 = \{BCE,ABC,ACE\}\)</span></p>
<h3 id="rule-generation">3. Rule Generation</h3>
<p>当我们得到所有满足minSUP的item后，我们还要找到满足minCONF的item，即<span class="math inline">\(\rightarrow\)</span>该是谁指向谁。</p>
<p>例如当我们知道item{A,B,C,D}满足minSUP，它有以下这么多种可能：</p>
<p><img src="image-20191107160738277.png"></p>
<p>总共会有<span class="math inline">\(2^{k-2}\)</span>种可能，k为item包含的个数。</p>
<p>对于confidence，我们能找到这样的关系：</p>
<p><img src="image-20191107161118117.png"></p>
<p>2个关系，左边多数的一定大。</p>
<p><img src="image-20191107161637990.png"></p>
<h3 id="maximal-frequent-itemset">Maximal Frequent Itemset</h3>
<p>一个itemset可以被称为Maximal Frequent Itemset当它是frequent并且它的下一层超集不是frequent的。</p>
<p><img src="image-20191107162038096.png"></p>
<p>例子：</p>
<p><img src="image-20191107162232045.png"></p>
<h3 id="closed-itemset">Closed itemset</h3>
<p>一个itemset是closed itemset，那么它的immediate superset的supports和它的support不一样。</p>
<p>例子：</p>
<p>我们有这样一个transaction</p>
<p><img src="image-20191107162626321.png"></p>
<p>计算support：</p>
<p><img src="image-20191107162704381.png"></p>
<p>黄色的部分就是closed itemset。</p>
<p>例如我们考虑{B}, S(B) = 5,</p>
<p>B的immediate supersets的support为S(A,B) = 4, S(B,C)=3, S(B,D) = 4</p>
<p>他们都不等于S(B)，因此B是closed itemset。</p>
<h2 id="v.-anomalyoutlier-异常值检测">V. Anomaly/Outlier 异常值检测</h2>
<h3 id="概念介绍">1. 概念介绍</h3>
<h4 id="什么是异常值">什么是异常值？</h4>
<blockquote>
<p>The set of data points that are <strong>considerably different</strong> from the remainder of the data</p>
<p>与其余数据有<strong>显着差异</strong>的一组数据点</p>
</blockquote>
<p>杠精提问1: 那怎么判断这个数据点是和其他的数据显著差异的呢？</p>
<h4 id="异常值检测可以用在哪">异常值检测可以用在哪？</h4>
<ul>
<li><p>数据清洗，异常值会造成错误的判断</p></li>
<li><p>把找出那个异常值当作目标，例如故障检测，网络入侵检测（因为异常值和正常值有很大的差异，所以它们可能会是故障或者人为故意的行为）</p></li>
</ul>
<h4 id="异常值outlier-和噪声noise是不是一个概念">异常值（outlier) 和噪声（noise）是不是一个概念？</h4>
<p><strong>不是！</strong></p>
<p>噪声是随机出现的错误。比如你输入的时候打错了字，别人填问卷调查的时候勾错了选项（不是故意的）。</p>
<p>异常值是<strong>真实发生</strong>的，但是和正常的数据不一样（例如绝地求生开挂的孤儿的数据变态的离谱）。因此，异常值是很有趣的而且有时候可以作为数据挖掘的目的（查出那些开挂的孤儿，再封掉它们）。</p>
<p>总结：</p>
<ul>
<li><p>噪声（noise）无论干嘛都是第一个需要被清洗掉的（噪声：我做错了什么）</p>
<p>杠精笑齐：那清洗噪声的方法呢？</p>
<p><del>（我的想当然：在实际情况中，噪声和异常值在用清洗方法的时候都同时被去掉了。而如果目的是找出异常值的话，在找到异常值和噪声的合集之后，根据业务逻辑来判断。因为噪声都是随机的错误，而异常值是有逻辑的，而且这个合集应该是比较小的，可以单独判断吧。</del></p>
<p>发邮件给老师后的回复：<a href="https://medium.com/@aatl2012/the-basic-difference-between-noise-and-outliers-in-data-cd3ff32343e0" target="_blank" rel="noopener">噪声和异常点的区别</a></p></li>
<li><p>异常值（outlier）经常在噪声被剔除后也被删掉，但也有可能项目目的就是检测出异常值。</p></li>
</ul>
<h4 id="异常值评估">异常值评估</h4>
<p>我们找出来的异常值是<strong>正确的，真的</strong>的异常值嘛？该怎么评估（evaluate）我这个方法找出来的异常值好不好？</p>
<p>很难界定，因为我们不知道正确答案啊。异常值检测也是无监督学习，他的评估和聚类（clustering）类似。</p>
<h4 id="异常值检测方案schema">异常值检测方案（schema）</h4>
<p>顾名思义，首先定义出正常的值（大部分的数据）。然后和我们定义的正常值有显著差异的值就是异常值了嘛。</p>
<h4 id="异常值类型">异常值类型</h4>
<ol type="1">
<li><p>全局异常值（Global outlier）：这个点和绝大多数正常值都有显著差异。（其实就是定义，最土味，最直观的，也是大多时候我们所要找的异常值）</p></li>
<li><p>Contextual outlier（上下文异常值？没找到专业的中文名词）：这个点和特定的上下文数据有显著差异。</p>
<p>一个方便理解的例子：今天温度40度，我们一般的天气20多度或者30多度。如果用全局异常值的方法，可能这个40还是包括在正常的浮动范围里的，但是40度是非常恐怖的天气，一定是算异常值的。这时候我们就要结合我们的上下文，即我们是在什么<strong>时间段</strong>？什么<strong>地点</strong>？ 等等上下文因素去考虑异常值。</p></li>
<li><p>集体异常（collective outlier）：单个的数据不是异常值，但是多个个体一起出现时一种异常。</p>
<p>某一户小区有一户人家搬走了，不是异常。十户人家一起搬走了，是一个异常。</p>
<p>一台电脑拒绝发送请求，可能突然fail了，不是异常。十台电脑拒绝发送请求，是异常，可能被黑客攻击了。</p>
<p>FPX的5个人每个人都不是变态强的选手，不是异常。5个人组合在一起贼猛，成第一名了是异常。</p>
<p>举例子实在太好玩了。</p></li>
</ol>
<h3 id="异常值检测的各种方法anomaly-detection">2. 异常值检测的各种方法（Anomaly Detection）</h3>
<h4 id="统计检验statistical-based">1.统计检验（Statistical-based）</h4>
<ul>
<li>假设这个数据集是根据一种随机过程（stochastic process） 产生的。就是说服从某种模型（例如正太分布）。</li>
<li>用各种数据拟合（data fitting）的方法，例如最小二乘，梯度下降，把这种分布表示出来，然后处于<strong>低概率</strong>的那些数据点就是异常值。</li>
</ul>
<ol type="1">
<li><p>有参数模型</p>
<p>假设这个数据集服从某种概率密度函数，例如我们假设数据集是服从我们最喜欢的正太分布。</p>
<p><img src="image-20191014213158445.png"></p>
<p>它需要参数：<strong>平均值，方差</strong></p>
<p>根据这个图我们知道，当我们的数据是在这个图里左右2.5%的时候，数据是异常值。</p>
<p><strong>杠精笑齐</strong>：那到底咋算啊？ 参数咋算啊？？这个2.5%又是什么东西啊？？？</p>
<p>正太分布的公式是这样的： <span class="math display">\[g(x)=\frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{1}{2}((x-\mu) / \sigma)^{2}}\]</span></p>
<p>其中<span class="math inline">\(\mu\)</span>是我们数据集的平均值，<span class="math inline">\(\sigma\)</span>是我们数据集的方差，这2个就是我们这个方法需要的求的参数！</p>
<p>2.5%不用管，有兴趣的可以去学习统计——概率密度函数。</p>
<p>但是根据经验表明，<span class="math display">\[ \mu \pm 3\sigma\]</span> 这一段数据在正太分布里可以涵盖99.7%的数据。</p>
<p>所以我们就计算：<span class="math display">\[ \mu \pm 3\sigma\]</span> ，只要我们的值 $ x &lt; - 3$ 或者 $ x &gt; + 3$ ,那x就是异常值！</p>
<p>这里直接把书中的例子搬过来：</p>
<p>​ 我们有一个数据集是{<span class="math inline">\({24.0, 28.9, 28.9, 29.0, 29.1, 29.1, 29.2, 29.2, 29.3, 29.4}\)</span>}, 并且我们知道它是服从正太分布的。（要好多假设条件😀）</p>
<p>​ 我们就能求出来: <span class="math inline">\(\hat{\mu}=28.61 , \hat{\sigma}=\sqrt{2.29}=1.51\)</span></p>
<p>​ 那<span class="math display">\[ \mu - 3\sigma = 24.08\]</span>,<span class="math display">\[ \mu + 3\sigma = 33.14\]</span></p>
<p>​ 大功告成，我们发现只有 <strong>24</strong> 是在这个区间外面的，所以<strong>24</strong>就是这个数据集的异常值！Bingo😉~</p>
<p>总结一下哈：这个方法要求的条件也太多了。</p>
<ul>
<li>第一要求数据集服从一种模型。实践中我们拿到一个数据集，这个数据集又不会告诉我们它是属于什么模型，什么概率分布的。</li>
<li>第二绝大多数只能应对一维的情况，就像我们的例子。但是实际操作我们的数据集特征都是少说也有十几个吧（年龄，性别等等）。对于一个高维的数据集，我们是很难去估计它服从什么分布的。（我不知道为什么，但是这学期的数学课推了一个二维的正太分布就挺复杂了，而且已经是三维的图了。所以这里只记了结论）</li>
</ul></li>
<li><p>无参数模型</p>
<p>我们想用一个概率分布去表达一个数据集的目的其实是为了找到数据集的<strong>正常值（normal data）</strong>。但是其实我们可以靠目测（听上去更加不靠谱）。就是我们识别这个<strong>正常值</strong>不用一个先规定好的结构/模型。</p>
<p>那我们用什么来预测？（都轮不到杠精笑齐来提问的问题） 用土味的histogram（直方图）</p>
<p><img src="image-20191014221044545.png"></p>
<p>假设这是一张交易记录的直方图，我们规定了bin（直方格）的长度是1。然后就出来了这个图。然后我们发现只有0.2%的交易是大于5000的。那所有在这个交易记录里面大于5000的都是<strong>异常值</strong>了。好简单好爽好快乐。</p>
<p><strong>杠精笑齐</strong>：那这个bin咋算？？我要是算bin是0.5一格的话，那是不是有可能5500以上的才是异常值啊？那我前面好简单好爽好快乐的方法说5100是异常值，这个又说5100不是异常值？你这个人靠不靠谱啊？？</p>
<p>所以这个方法我觉得应该也算是有参数的，参数就是bin的取值。</p>
<p>bin取值带来的问题：</p>
<ul>
<li><p>bin值太大：那就会让有的异常点跑到正常值里面去了。想象一下我们只有一个bin（这个bin值就是全数据集的长度），这个bin的频率是100%，异常值都跑到bin里面去了。false negative</p></li>
<li><p>bin值太小：那我们的正常值可能会被判断成异常值了，想象一下我们有N个bin（N就是我们数据集的长度），这样我们每个数据点的频数都是1，频率都是一样且非常小，那每个数都是异常值了。false positive</p>
<p>这里的false negative和false positive是第一张分类混淆矩阵（confusion matrix）的知识内容，被混淆了的同学请前往<a href="#混淆矩阵（confusion%20matrix）">混淆矩阵</a>。</p></li>
</ul></li>
</ol>
<h4 id="接近度proximity-based">2. 接近度（Proximity-based）</h4>
<h5 id="基于距离distance">1. 基于距离（distance）</h5>
<p>直接给出公式</p>
<p><span class="math display">\[ {\frac{\left\|\left\{o^{\prime} | \operatorname{dist}\left(o, o^{\prime}\right) \leq r\right\}\right\|}{\|D\|} \leq \pi}\]</span></p>
<p>好懵逼🤣，没事。</p>
<p>原理就是</p>
<ol type="1">
<li>你自己定义一个距离。</li>
<li>然后计算所有数据点和现在在判断是不是异常值的这个数据点的距离。</li>
<li>数出有多少个点是在你自己定义的距离里面的，就是<strong>步骤2</strong>的距离小于<strong>步骤1</strong>的距离。</li>
<li>把<strong>步骤3</strong>数出来的数除以数据集的长度（有多少个数据点），如果小于一定的比例，就是异常值。</li>
</ol>
<p>还是好懵逼🤣</p>
<p>首先 <span class="math inline">\(\pi\)</span>和<span class="math inline">\(r\)</span> 是我们自己设计的值。<span class="math inline">\(r\)</span> 就是<strong>步骤1</strong>的距离。$ $ 不是那个3.1415……，是<strong>步骤4</strong>的那个比例，也是一个我们设计的0到1之间到百分数。<span class="math inline">\(o^{\prime}\)</span> 代表所有其他数据点。</p>
<p>$ {O^{} | (O, O^{}) r}$ 代表<strong>步骤2</strong> ，<span class="math inline">\(\|D\|\)</span> 和分子的 ||…|| 都代表cardinality（基数），就是有多少个，<strong>步骤3</strong>和<strong>步骤4</strong></p>
<p>应该懂了，在加深一下，所以我们可以定义 <span class="math inline">\(k=\pi\|D\|\)</span>, 那k其实也代表一个threshold（阈（yu）值），它的意义是如果你<strong>步骤3</strong>数出来的基数（个数）少于 <span class="math inline">\(k\)</span> 的话，这个值就是异常值。</p>
<p>现在考虑一下优化方法，作为一个未来的数据科学家，经常处理特别大的数据集，不学优化等于每一次调试都要等很久<del>或者想要买一台新的电脑</del></p>
<p>优化： 如果<strong>步骤3</strong>已经数到了<span class="math inline">\(k\)</span>个值，就停止循环。（没必要继续继续下去了，这个数据集已经证明自己不是异常值了，我们不需要知道它有多靠近数据集的中心）</p>
<h5 id="基于密度density-based-outlier-detection">2. 基于密度（Density-Based Outlier Detection）</h5>
<p>不像上一种方法用一个数据值和所有其他数据值比较，我们只比较和它相邻的数据。</p>
<p><img src="image-20191015101212861.png"></p>
<p>如图，根据不靠谱的目测，我们觉得</p>
<blockquote>
<p><span class="math inline">\(O_1,O_2\)</span>是<span class="math inline">\(C_1\)</span>的异常值，<span class="math inline">\(O_1,O_2\)</span>就是<strong>局部异常值</strong>（只针对<span class="math inline">\(C_1\)</span>）</p>
<p><span class="math inline">\(O_3\)</span>是<strong>全局异常值</strong></p>
<p><span class="math inline">\(O_4\)</span>是正常值，不是异常值。</p>
</blockquote>
<p>但是，试想一下我们用前面的一种检测方法（基于距离），我们是找不到<span class="math inline">\(O_1,O_2\)</span>是异常值的。（因为它们离<span class="math inline">\(C_1\)</span>其实挺近的。）</p>
<p>但是基于密度的方法我们是可以找的。</p>
<p>这个方法课件里面说是用最低的LOF值，tutorial里说用最高的LOF值是异常值，把我搞混了很久，老师回复邮件后搞懂。</p>
<p><img src="1920px-LOF-idea.svg.png"></p>
<p>基本思想：比如我们检测A是不是一个异常值，我们是比较<strong>A的密度和A密度范围里面其他点的密度的平均值</strong>。</p>
<p>怎么比呢？就是用它们的比值，它有一个特别的名字（LOF: Local outlier factor)。</p>
<p>这里分子是范围内点们密度平均值，分母是A的密度</p>
<ol type="1">
<li>如果这个比值接近1: 说明A的密度和它范围内的点们的密度都差不多，那就说明不是离群点了。</li>
<li>如果这个比值小于1: 说明A的密度比范围内的点们大，A更靠近它们。</li>
<li>如果这个比值大于1: 说明A的密度比范围内的点们的密度平均值小，A是异常值。</li>
</ol>
<p>杠精笑齐：</p>
<ol type="1">
<li><p>这个范围是怎么定义的？为什么图里面A的范围那么大，在A范围里的那3个点的范围那么小？</p></li>
<li><p>这个密度是从哪里冒出来的，咋算啊？</p></li>
</ol>
<p>范围：离要检测的点最近的第K个点的距离是这个检测的范围。</p>
<p>​ 图中我们选的<span class="math inline">\(K=3\)</span>, 所以A里面包含了3个点，其他的点的范围也都是3个点。</p>
<p>​ 这样就避免了我们基于距离方法的问题，我们现在定义的距离是动态的，是能根据不同的点来变 换的。</p>
<p>密度：其实更具体的名词是<strong>局部可达性密度（lrd）</strong></p>
<p>​ <del>密度等于质量除以体积</del> —— 不是你想的那样。 但是核心思想差不多啦，就是我们想知道在这个检测点密不 密集。但是这个事情是非常难用数学表达出来的（对我们学渣还非常难理解😱这么多数学符号是什么鬼 啦，为了让大家查阅其他资料的时候符号一样，下面我也被迫使用这么多不想看明白的数学符号）。</p>
<p>​ 质量：是我们的规定的K。图中的例子就是 <span class="math inline">\(3\)</span>.</p>
<p>​ 很多用<span class="math inline">\(|N_{k}(A)|\)</span>表示，其中<span class="math inline">\(N_{k}(A)\)</span> 就是被A的范围包含的点们的集合。<span class="math inline">\(|x|\)</span>代表x的基数（个数）。</p>
<p>​ 明明就是 K嘛，为什么要这么复杂。。。要是我理解错了请告诉我。</p>
<p>​ 为什么要用K呢，因为这样我们所有的点的分子都是一样的了，看它们密不密集，就看分母了。</p>
<p>​ 体积： 是我们<span class="math inline">\(N_{k}(A)\)</span>里所有点到A的距离和。</p>
<p>​ 然而距离不是单纯的距离，有一个新的距离定义方式叫<strong>可达距离</strong></p>
<p>​ reachability-distance <span class="math inline">\(r-d(A,C) = max(k-distance(C),d(A,C))\)</span></p>
<p>​ <span class="math inline">\(k-distance(C)\)</span>是C的范围。</p>
<p>​ 也就是当我们算A范围里其他点（例如C）对A的距离的时候，这个距离<strong>至少得是C的范围</strong>。</p>
<p>​ （其中理论我也没懂，求大神解释）</p>
<p>​ 密度计算公式：</p>
<p>​ <span class="math inline">\(\operatorname{lrd}_{k}(A):= \frac {|N_{k}(A)|}{\sum_{B \in N_{k}(A)} {reachability-distance}_{k}(A, B)}\)</span></p>
<p>​ 分子就是我们说的质量嘛，分母就是我们说的体积嘛。</p>
<p>终于到LOF了，现在我们再来看我们的基本思想：比较<strong>A的密度和A密度范围里面其他点的密度的平均值</strong>。</p>
<p>我们已经会求密度了，直接看公式：</p>
<p>​ <span class="math inline">\(\operatorname{LOF}_{k}(A) = \frac{\sum_{B \in N_{k}(A)} \operatorname{lrd}(B)}{\left|N_{k}(A)\right|} / \operatorname{lrd}(A)\)</span></p>
<p>左半部分<strong>A密度范围里面其他点的密度的平均值</strong>，右半部分<strong>A的密度</strong></p>
<p>现在也很好理解为什么tutorial里面说高的LOF值是异常值，课件里面说低的LOF值是异常值了。</p>
<p>因为它们的比值分子分母反了。。。分子分母反了。。。反了。。。</p>
<p>为了应付考试的步骤流程图：</p>
<ol type="1">
<li>根据题目给的K值和定义距离的方法（曼哈顿，欧几里得）找出每个点的k-distance（范围）</li>
<li>找出每个点里面k-distance（范围）里面的其他点</li>
<li>计算所有点的密度</li>
<li>计算每个点的LOF</li>
<li>看你怎么比决定取最大值还是最小值作为异常值。</li>
</ol>
<p>（终于完了，唯一一个疑惑的就是<strong>可达距离</strong>的含义了）</p>
<p>总结：</p>
<blockquote>
<p>基于距离：异常值的附近不够满足你要求的点的数量。</p>
<p>基于密度：异常值的密度不够满足你要求的密度。</p>
</blockquote>
<h4 id="聚类检验cluster-based">3. 聚类检验（cluster-based）</h4>
<p><img src="image-20191015110704026.png"></p>
<p>看图就明白了，把数据集用某种聚类方法聚类。</p>
<blockquote>
<p>1.这个点到属于它的类的类中心的距离非常的长</p>
<p>2.包含很小数量的聚类都是<strong>异常值</strong>。</p>
</blockquote>
<p>第一种情况：</p>
<p>​ 那我们就计算这个点<span class="math inline">\(o\)</span>到类中心<span class="math inline">\(c\)</span>到距离<span class="math inline">\(d(o,c)\)</span>,和其他属于这个类的点们<span class="math inline">\(o_i\)</span>到类中心<span class="math inline">\(c\)</span>的距离平均值<span class="math inline">\(d(o_i,c)_{avg}\)</span>,然后计算它们的比值，如果这个比值很大，说明这个点<span class="math inline">\(o\)</span>就是异常值。 用比值的原因就是给我们一个关于这个类本身大小的判断依据，不然有的类很大，有的类很小。如果只根据距离定义阈值会出现错误。</p>
<p>第二种情况：</p>
<p>​ 假设有一个数据点<span class="math inline">\(p\)</span></p>
<p>​ 如果<span class="math inline">\(p\)</span>在一个比较大的聚类<span class="math inline">\(c_1\)</span>里面：</p>
<p>​ <span class="math inline">\(CBLOF = c_1的size \times p和c_1的相似度\)</span></p>
<p>​ 如果<span class="math inline">\(p\)</span>在一个比较小的聚类<span class="math inline">\(c_2\)</span>里面：</p>
<p>​ <span class="math inline">\(CBLOF = c_2的size \times p和离它最近的大聚类的相似度\)</span></p>
<p>相似度有很多种不同的方式。CBLOF比较小的值就是异常值。 （2个参数，相似度低或者类比较小，就代表离群了）</p>
<hr>
<h2 id="vi.-recommender-systems">VI. Recommender Systems</h2>
<h3 id="user-based">1. User-based</h3>
<p><img src="image-20191108094208703.png"></p>
<h4 id="pearson-correlation">Pearson correlation</h4>
<p>使用pearson相关系数来作为相似度的考量</p>
<p><img src="image-20191108094303685.png"></p>
<p>其实和我们介绍过的<a href="#Cosine%20Similarity">cosine similarity</a>非常相似：</p>
<p>在cosine similarity中：$ (a, b)=$</p>
<p>上面就是两条向量的点积，下面是各自向量的模</p>
<p>而pearson这个人就是把cosine similarity做了个中心标准化（每一项都减去平均值），就像正太分布变成标准正态分布一样。</p>
<p>例子：计算Alice对于“Item5”可能的评分（兴趣）是多少？</p>
<p>思路：</p>
<ol type="1">
<li>计算Alice和所有其他user的similarity</li>
<li>根据你选用的neighbor策略（选k个相关的user作为参考）选相似度最高的k个user</li>
<li>根据那k个uesr的item5评分，计算<span class="math inline">\(\operatorname{pred}(\boldsymbol{a}, \boldsymbol{p})=\overline{\boldsymbol{r}_{a}}+\frac{\sum_{b \in N} \operatorname{sim}(\boldsymbol{a}, \boldsymbol{b}) *\left(\boldsymbol{r}_{b, p}-\overline{\boldsymbol{r}}_{b}\right)}{\sum_{b \in N} \operatorname{sim}(\boldsymbol{a}, \boldsymbol{b})}\)</span></li>
</ol>
<p>计算：</p>
<ol type="1">
<li><span class="math inline">\(\hat{Alice}=4,\hat{user1}=2.25\)</span>, <strong>注意这里user1的平均值不包括item5，后面的计算也不包括，item5的值仅在预测那一步使用）</strong>，<span class="math inline">\(sim(Alice,user1) = \frac{(5-4)(3-2.25)+(3-4)(1-2.25)+(4-4)(2-2.25)+(4-4)(3-2.25)}{\sqrt{(5-4)^2+(3-4)^2}\times \sqrt{(3-2.25)^2+(1-2.25)^2+(2-2.25)^2+(3-2.25)^2}}= 0.85\)</span></li>
<li>同理可得<span class="math inline">\(sim(Alice,user2) = 0.7\)</span>, <span class="math inline">\(sim(Alice,user3) = 0\)</span>, <span class="math inline">\(sim(Alice,user4) = -0.79\)</span></li>
<li>我们选用2-nearest neighbours: user1和user2</li>
<li><span class="math inline">\(Pred(Alice,item5) = \hat{Alice} + \frac{sim(Alice,user1)*(user1.item5-\hat{user1}+sim(Alice,user2)*(user2.item5-\hat{user2})}{sim(Alice,user1)+sim(Alice,user2)} = 4+\frac{0.85\times (3-2.25)+0.7\times(5-3.5)}{0.85+0.7} = 5.08\)</span></li>
</ol>
<h4 id="peason-correlation的缺点">Peason correlation的缺点</h4>
<ol type="1">
<li>并非所有邻居的评分都同样“有价值” –就普遍喜欢的商品达成协议并没有像对有争议的商品达成协议那样内容丰富 –可能的解决方案：对具有较大差异的项目给予更多权重</li>
<li>共同项目数的值 –同时考虑皮尔逊相似性和共同评定项目的数量</li>
<li>案例放大 –直觉：给予“非常相似”的邻居更多的权重，即相似度值接近1的邻居。</li>
<li>neighborhood选择 –使用相似性阈值或固定数目的邻居</li>
</ol>
<h3 id="item-based">2. Item-based</h3>
<p><img src="image-20191108102944155.png"></p>
<p>简单的说就是user-based就用user向量（行向量），item-based就是用item向量（列向量）。</p>
<h3 id="latent-factor-modellfm">3.Latent Factor Model(LFM)</h3>
<p>我们将传统的用户/商品表格，转变为“商品-商品属性”与“商品属性-用户喜好”2个表格</p>
<p>即如下格式：<span class="math inline">\(A_{m \times n}=U_{m \times k} V_{K \times n}\)</span></p>
<p>我们有如下原始表格（0表示没有评价，需要我们预测）</p>
<p><img src="image-20191108110747662.png"></p>
<p>我们想得到矩阵U和矩阵V，就是构造函数然后使loss function（损失函数）最小即公式：</p>
<p><span class="math inline">\(J(U, V ; A)=\sum_{i=1}^{m} \sum_{j=1}^{n}\left(a_{i j}-\sum_{r=1}^{k} u_{i r} \cdot v_{r j}\right)^{2}+\lambda\left(\sum_{i=1}^{m} \sum_{r=1}^{k} u_{i r}^{2}+\sum_{j=1}^{n} \sum_{r=1}^{k} v_{r=1}^{2}\right)\)</span></p>
<p>等式右边的第一项就是我们的损失函数，第二项是L2正则化项（对应于redge回归的正则化），可以降低解决过拟合问题导致分解后的矩阵元素太大（背就完事了）</p>
<p>对我们的构造函数求梯度：</p>
<p><span class="math inline">\(\left\{\begin{array}{l}{\frac{\partial J(U, V ; A)}{\partial u_{i r}}=-2\left(a_{i j}-\sum_{r=1}^{k} u_{i r} v_{r j}\right) \cdot v_{r j}+2 \lambda u_{i r}} \\ {\frac{\partial J(U, V ; A)}{\partial v_{r j}}=-2\left(a_{i j}-\sum_{r=1}^{k} u_{i r} v_{r j}\right) \cdot u_{i r}+2 \lambda v_{r j}}\end{array}, 1 \leq r \leqslant k\right.\)</span></p>
<p>然后因为数据量过大所以选用SGD（随机梯度下降法，<a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent" target="_blank" rel="noopener">Stochastic gradient descent</a>）</p>
<p>求得U和V矩阵后相乘，可以发现所得结果接近原矩阵，并且原先为0的点有数值了（即预测值）</p>
<p>LFM的优点：</p>
<ol type="1">
<li>high accuracy</li>
<li>Auto group items –</li>
<li>Scalability is good –</li>
<li>Learning-based</li>
</ol>
<p>缺点：</p>
<ol type="1">
<li>Incremental updating</li>
<li>Real-time –</li>
<li>Explanation</li>
</ol>
<h3 id="model-based">4. Model-based</h3>
<p>用我们前面学过的各种模型来进行对rating的预测</p>
<h4 id="bayes">1. Bayes</h4>
<p><a href="#3.%20Naïve%20Bayes（朴素贝叶斯">复习</a></p>
<p>例如我们有这样一个表：</p>
<p><img src="image-20191108113503171.png"></p>
<p>计算<span class="math inline">\(P(Item1 = 1, Item2 = 3, Item3 =3, Item4 =2|Item5 = 1)\)</span></p>
<p><span class="math inline">\(P(Item1 = 1, Item2 = 3, Item3 =3, Item4 =2|Item5 = 2)\)</span></p>
<p><span class="math inline">\(P(Item1 = 1, Item2 = 3, Item3 =3, Item4 =2|Item5 = 3)\)</span></p>
<p><span class="math inline">\(P(Item1 = 1, Item2 = 3, Item3 =3, Item4 =2|Item5 = 4)\)</span></p>
<p><span class="math inline">\(P(Item1 = 1, Item2 = 3, Item3 =3, Item4 =2|Item5 = 5)\)</span></p>
<p>选最高的概率</p>
]]></content>
      <categories>
        <category>Data Mining</category>
      </categories>
      <tags>
        <tag>Data Mining</tag>
      </tags>
  </entry>
</search>
