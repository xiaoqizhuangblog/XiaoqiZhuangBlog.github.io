<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Contrastive Learning,">










<meta name="description" content="Contrastive Learning (1) InstDisc This article aims to introduce the pioneering work (InstDisc) that leads to contrastive learning. Paper: Zhirong Wu, Yuanjun Xiong, Stella Yu, and Dahua Lin. Unsuperv">
<meta name="keywords" content="Contrastive Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="Contrastive Learning (1) InstDisc">
<meta property="og:url" content="http://yoursite.com/2022/02/28/Contrastive Learning (1) InstDisc/index.html">
<meta property="og:site_name" content="Xiaoqi">
<meta property="og:description" content="Contrastive Learning (1) InstDisc This article aims to introduce the pioneering work (InstDisc) that leads to contrastive learning. Paper: Zhirong Wu, Yuanjun Xiong, Stella Yu, and Dahua Lin. Unsuperv">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://yoursite.com/images/image-20220228230043662.png">
<meta property="og:image" content="http://yoursite.com/images/image-20220228231908238.png">
<meta property="og:image" content="http://yoursite.com/images/InstDisc.png">
<meta property="og:image" content="http://yoursite.com/images/memory%20bank.png">
<meta property="og:updated_time" content="2022-04-19T13:29:13.161Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Contrastive Learning (1) InstDisc">
<meta name="twitter:description" content="Contrastive Learning (1) InstDisc This article aims to introduce the pioneering work (InstDisc) that leads to contrastive learning. Paper: Zhirong Wu, Yuanjun Xiong, Stella Yu, and Dahua Lin. Unsuperv">
<meta name="twitter:image" content="http://yoursite.com/images/image-20220228230043662.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2022/02/28/Contrastive Learning (1) InstDisc/">





  <title>Contrastive Learning (1) InstDisc | Xiaoqi</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Xiaoqi</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Why always me?</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/02/28/Contrastive Learning (1) InstDisc/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Xiaoqi Zhuang">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiaoqi">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Contrastive Learning (1) InstDisc</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-02-28T23:55:42+08:00">
                2022-02-28
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="contrastive-learning-1-instdisc">Contrastive Learning (1) InstDisc</h1>
<p>This article aims to introduce the pioneering work (InstDisc) that leads to contrastive learning.</p>
<p>Paper: Zhirong Wu, Yuanjun Xiong, Stella Yu, and Dahua Lin. Unsupervised feature learning via non-parametric instance discrimination. In CVPR, 2018. Updated version accessed at: https://arxiv.org/abs/1805.01978v1.</p>
<a id="more"></a>
<h1 id="why-this-paper">Why this paper?</h1>
<p>Self-supervised models such as BERT/GPT have been used with great success in the NLP field. However, supervised learning still occupies most of the work in the CV field. Researchers hope to find a kind of pretext task in the image domain to complete self-supervised learning, just like MASK in the NLP domain. This paper creatively proposes a pretext task called <strong>instance discrimination</strong> which performs well and is still the most mainstream pretext task for contrastive learning so far.</p>
<p>Although techniques about the loss function, how negative samples are stored in this paper are obsolete, the pretext task and the framework in this paper has a milestone significance in the history of contrastive learning and has influenced most of the subsequent work.</p>
<p>Hence, I choose this paper as the first one in this series of the survey of contrastive learning.</p>
<h1 id="research-motivation">Research Motivation</h1>
<figure>
<img src="/images/image-20220228230043662.png" alt="image-20220228230043662"><figcaption>image-20220228230043662</figcaption>
</figure>
<p>Paper’s Figure 1 is very clear to show the motivation. Authors find that:</p>
<blockquote>
<p>For an image from class <em>leopard</em>, the classes that get highest responses from a trained neural net classifier are all visually correlated, e.g., <em>jaguar</em> and <em>cheetah</em>. It is not the semantic labeling, but the apparent similarity in the data themselves that brings some classes closer than others.</p>
</blockquote>
<p>Hence, they want to:</p>
<blockquote>
<p>Our unsupervised approach takes the class-wise supervision to the extreme and learns a feature representation that discriminates among individual instances.</p>
</blockquote>
<p>In other words, contrastive learning is also called representation learning which aims to find an image vector(like word vector in NLP) which represents image semantic in a high dimension by unsupervised learning. And then, you can use these vector in your custom downstream tasks with a small annotated dataset.</p>
<h1 id="model-overview">Model Overview</h1>
<figure>
<img src="/images/image-20220228231908238.png" alt="image-20220228231908238"><figcaption>image-20220228231908238</figcaption>
</figure>
<p>Figure 2 shows a clear pipeline of the model inference. Now I will describe each part of them and try to make you understand easier.</p>
<h2 id="instance-discrimination">Instance Discrimination</h2>
<p>As figure 1 says, we want to get a vertor which similar images are close in a high dimension(128 in this paper) and not similar images are far way from each other without using annotated images. However, although InstDict model is called as a unsupervised model, they actually still uses label. The method they use is really tricky that they take every image as a class and the task is to distinguish every image instance. This task sounds useless, and yes they are. So this kind of task is named as pretext task, which the aim of them is just to let the model can be trained.</p>
<figure>
<img src="/images/InstDisc.png" alt="InstDisc"><figcaption>InstDisc</figcaption>
</figure>
<p>Above figure shows that a pipline of instance discrimination. An instance, in this example , is an image of a unqiue cat. it will be transferred by image augmentation into 2 images: cropped one and rotated one. These two represent the same cat and so the image vector of these 2 images should be similar in our model, and vertors of other images in red square should be quite different from these 2images. What you find? Yes, we get positive and negative sample by this kind of easy implementation. Usually, in contrastive learning, we call the “cropped cat” (one of the augmentation image) Query, and the combination of the other augmentation image and the rest images is called Keys. Hence, our aim is to find a key in keys which is most similar with the query.</p>
<p>To conclusion, instance discrimination is a tricky pretext task which make the images without labels can have similar label by using image augmentation.</p>
<p>Pros: easy to implementation, good explanation, proved to be useful</p>
<p>Cons: the negative samples may contain the positive sample(image another cat image is included but it will be treated as a negative sample in instance discrimination task)</p>
<h2 id="loss-function-nce-loss">Loss Function: NCE loss</h2>
<p><span class="math inline">\(Loss = -\log\frac{\exp \left(\mathbf{v}_{i}^{T} \mathbf{v} / \tau\right)}{\sum_{j=1}^{n} \exp \left(\mathbf{v}_{j}^{T} \mathbf{v} / \tau\right)}\)</span></p>
<p><span class="math inline">\(v_i\)</span> is query, <span class="math inline">\(v\)</span> is positive key, <span class="math inline">\(v_j\)</span> are negative keys. The loss function is similar with Cross Entropy Softmax.</p>
<p>Actually, InfoNCE is totally the same as NCE loss, which infoNCE uses n (n &lt; j) samples instead of all negative samples to make calculation faster.</p>
<h2 id="memory-bank">Memory Bank</h2>
<p>Another important work in InstDisc is that it proposed a data structure called memory bank, which stored all images’ 128d vectors, also the <span class="math inline">\(v_j\)</span> in the loss function.</p>
<p>Pipeline in Paper:</p>
<blockquote>
<p>Let V = {vj} be the memory bank and fi = fθ(xi) be the feature of xi. During each learning itera- tion, the representation fi as well as the network parameters θ are optimized via stochastic gradient descend. Then fi is updated to V at the corresponding instance entry fi → vi. We initialize all the representations in the memory bank V as unit random vectors.</p>
</blockquote>
<p>A more clear flowchart:</p>
<figure>
<img src="/images/memory%20bank.png" alt="memory bank"><figcaption>memory bank</figcaption>
</figure>
<p>Pros: The number of negative samples in the previous comparative learning is not enough because it is strongly related to the batch size. Memory bank liberates this limation. In this paper, Each time nce loss is calculated, 4096 negative samples are randomly selected from the memory bank.</p>
<p>Cons: encoder network may update too quickly to make the distribution between image vectors has a large difference.</p>
<h2 id="evaluation">Evaluation</h2>
<p>Since contrastive learning is unsupervised learning and aims to learn good representation feature of images, we cannot directly assess the accuracy of the model.</p>
<p>InstDisc uses <strong>linear SVM</strong> and <strong>KNN</strong> to evaluate model performance. Simply, it is to use the encoder after model training as a feature extractor, and train a svm or knn on the features of the image after the encoder to evaluate model performance.</p>
<p>However, since this is a contrastive learning survey, I want to describe a more popular way in later works: <strong>Linear Classification Protocol</strong>. This method also freezes features from trained encoder, and train a supervised linear classifier(a fully-connected layer followed by softmax) and evualte different models between supervised and unspervised models. And ImageNet is always used as evaluation method.</p>
<p>InstDisc only has 54% accuracy on ImageNet by linear classification, which is much lower than supervised model. But it is a groundbeaking work and the following contrastive models have achieved the same performance with supervised model.</p>
<p>We will have a global description of model performance after we has discussed several classic contrastive learning models in following chapters.</p>
<h2 id="conclusion">Conclusion</h2>
<p>We describe the pretext task: Instance Discrimination, model pipeline, a brief of NCE loss and Memory bank. Actually, this paper also proposed other technique skills, but these techniques have little inspiration for follow-up research.</p>
<p>Next blog we will continue discussing another kinds of contrastive learning framework which are different from InstDisc.</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Contrastive-Learning/" rel="tag"># Contrastive Learning</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/02/29/DATA7202-1st-Week-Review/" rel="next" title="DATA7202 多元线性回归">
                <i class="fa fa-chevron-left"></i> DATA7202 多元线性回归
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2022/03/02/Contrastive Learning (2) SimCLR/" rel="prev" title="Contrastive Learning (2) SimCLR">
                Contrastive Learning (2) SimCLR <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Xiaoqi Zhuang</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#contrastive-learning-1-instdisc"><span class="nav-number">1.</span> <span class="nav-text">Contrastive Learning (1) InstDisc</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#why-this-paper"><span class="nav-number">2.</span> <span class="nav-text">Why this paper?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#research-motivation"><span class="nav-number">3.</span> <span class="nav-text">Research Motivation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#model-overview"><span class="nav-number">4.</span> <span class="nav-text">Model Overview</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#instance-discrimination"><span class="nav-number">4.1.</span> <span class="nav-text">Instance Discrimination</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#loss-function-nce-loss"><span class="nav-number">4.2.</span> <span class="nav-text">Loss Function: NCE loss</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#memory-bank"><span class="nav-number">4.3.</span> <span class="nav-text">Memory Bank</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#evaluation"><span class="nav-number">4.4.</span> <span class="nav-text">Evaluation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#conclusion"><span class="nav-number">4.5.</span> <span class="nav-text">Conclusion</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Xiaoqi Zhuang</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
